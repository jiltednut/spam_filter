{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Liam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Liam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import bz2\n",
    "import tarfile\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Language processing\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# URL libs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to specify where to get the email data (lib_url) and where to save it (main_dir, sub_dir)\n",
    "# These will be referenced in the data curation phase of execution.\n",
    "lib_url = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "main_dir = \"data\"\n",
    "sub_dir = \"extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_structure(main_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Function to create the directory structure on disk in the case that it doesn't already exist\n",
    "    The directory will be created in the same directory as the source file and will use the structure main_dir/sub_dir\n",
    "    Input:\n",
    "        main_dir: the top level of the directory structure\n",
    "        sub_dir: sublevel in the directory structure\n",
    "    Returns:\n",
    "        No return.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(\".\\\\\" + main_dir)\n",
    "    except:\n",
    "        print(\"Directory already exists.\")\n",
    "        try:\n",
    "            os.mkdir(\".\\\\\"+ main_dir +\"\\\\\"+ sub_dir +\"\\\\\")\n",
    "        except:\n",
    "            print(\"Directory already exists.\")\n",
    "    print(\"Directory Structure Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_email_records(url):\n",
    "    \"\"\"\n",
    "    Function to download the page source from online directory and create a list of filenames with .tar.bz2 extensions\n",
    "    Input:\n",
    "        url: the lib_url defined in the source\n",
    "    Returns:\n",
    "        downloadable: a list of urls made of the lib_url web address and the filenames extracted from the hyperlines in the page source.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(lib_url).text)\n",
    "    urls = soup.find_all('a')\n",
    "    filenames = [url['href'] for url in urls if \"bz2\" in str(url)]\n",
    "    downloadable = [lib_url + filename for filename in filenames]\n",
    "    print(\"Email archive urls extracted\")\n",
    "    return downloadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_email_records(file_urls):\n",
    "    \"\"\"\n",
    "    Function to download the email archives and write them to disk in the directory hierarchy\n",
    "    Input:\n",
    "        file_urls: a list of urls pointing to the email archives\n",
    "    Returns:\n",
    "        No return.\n",
    "    \"\"\"\n",
    "    for i, url in enumerate(file_urls):\n",
    "        dl = requests.get(url, allow_redirects = True)\n",
    "        open(\".//\" + main_dir + \"//\"+file_urls[i].split(\"/\")[-1], 'wb').write(dl.content)\n",
    "    print(\"Email archives downloaded from url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_records(main_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Function to extract the email records from the downloaded email archives.\n",
    "    Loops through all files in each level of the directory hierarchy and extracts the data from all tar.bz2 archives to disk.\n",
    "    Input:\n",
    "        main_dir: the top level of the directory structure\n",
    "        sub_dir: sublevel in the directory structure\n",
    "    Returns:\n",
    "        No return.\n",
    "    \"\"\"\n",
    "    for filepath in glob.glob(\".\\\\\" + main_dir + \"\\\\*.tar.bz2\"):\n",
    "        #zipfile = bz2.BZ2File(filepath)\n",
    "        #data = zipfile.read()\n",
    "        #newfile = filepath[:-4]\n",
    "        #open(newfile, \"wb\").write(data)\n",
    "        tar = tarfile.open(filepath, \"r:bz2\")\n",
    "        tar.extractall(os.path.join(main_dir+ \"\\\\\"+ sub_dir, filepath[7:-8]))\n",
    "        tar.close()\n",
    "    print(\"Email records extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_and_create_email_records(url, main_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Wrapper function to download and create the email records from the archive.\n",
    "    \"\"\"\n",
    "    urls = download_email_records(url)\n",
    "    create_directory_structure(main_dir = main_dir, sub_dir = sub_dir)\n",
    "    save_email_records(file_urls = urls)\n",
    "    extract_email_records(main_dir = main_dir, sub_dir = sub_dir)\n",
    "    print(\"Email records downloaded & extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_directory_details(target_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Function to traverse a directory and record the target type of each folder by checking if the folder\n",
    "    contains either \"HAM\" or \"SPAM\" in the name.\n",
    "    Input:\n",
    "        target_dir: the target directory\n",
    "        sub_dir: the sub directory\n",
    "    Returns:\n",
    "        email_type_names: a list containing the folder path, in the sub_dir, and the target type based on the folder name.\n",
    "    \"\"\"\n",
    "    sub_directories = glob.glob(target_dir + \"\\\\\"+ sub_dir +\"\\\\*\\\\*\")\n",
    "#     print(target_dir)\n",
    "#     print(os.path.join(target_dir, \"\\\\extracted\\\\*\\\\*\"))\n",
    "#     print(sub_directories)\n",
    "    names = [(x.split(\"\\\\\")[-1], \"HAM\" if x.find(\"ham\") >=0 else \"SPAM\") for x in sub_directories]\n",
    "    email_type_names = list(zip(names, sub_directories))\n",
    "    print(\"Target directories extracted\")\n",
    "    return email_type_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(email, line_names, target):\n",
    "    \"\"\"\n",
    "    Function to take in the filename of an email document.\n",
    "    Extract any information relating to the predefined tags\n",
    "    Store any information after the subject line as body - to be further processed later\n",
    "    Input:\n",
    "        email: the email text file, extracted from the email archive\n",
    "        line_names: a predefined list of line start strings that will correspond to column headers later\n",
    "        target: the target type extracted from the home folder of the email file.\n",
    "    Returns:\n",
    "        value_dict: a dictionary with the extracted body text, target type and key-value pairs for the line_names values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(email) as file:\n",
    "            body_start = False # Changed to True after reading the subject tag.\n",
    "            body = []\n",
    "            value_dict = {}\n",
    "            value_dict['target'] = target\n",
    "\n",
    "            for line in file.readlines():\n",
    "                line_start = line.split(\":\")[0]+\":\"\n",
    "                if body_start:\n",
    "                    body.append(line.strip())\n",
    "                if line_start in line_names:\n",
    "                    line_contents = re.findall(r\":\\s(.*)\", line)[0]\n",
    "                    value_dict[line_start] = line_contents\n",
    "                if line_start == \"Subject:\":\n",
    "                    body_start = True\n",
    "            value_dict['body'] = \"\\n\".join(body)\n",
    "            return value_dict\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: Error: Can't read file {email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_target_mappings(main_dir):\n",
    "    \"\"\"\n",
    "    Function to map the target type to the folder name.\n",
    "    Used to map the target to the individual email text files later.\n",
    "    Input:\n",
    "        main_dir: The directory that needs to be mapped\n",
    "    Returns:\n",
    "        target_mapping: list of tuples containing the folder path & the target type (\"HAM\" or \"SPAM\").    \n",
    "    \"\"\"\n",
    "    email_type_names = get_target_directory_details(\".\\\\\" + main_dir, sub_dir)\n",
    "    directories = [x[1] for x in email_type_names]\n",
    "    targets = [x[0][1] for x in email_type_names]\n",
    "    target_mapping = list(zip(directories, targets))\n",
    "    print(\"Target mappings extracted\")\n",
    "    return target_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_file_listing(dir_path):\n",
    "    \"\"\"\n",
    "    Function to create a list of all the file paths in a directory\n",
    "    Input:\n",
    "        dir_path: the file path of a directory\n",
    "    Returns:\n",
    "        a list of all files in the directory.\n",
    "    \"\"\"\n",
    "    print(dir_path + \"\\\\\")\n",
    "    return glob.glob(dir_path + \"\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_data_to_dictionary(main_dir):\n",
    "    \"\"\"\n",
    "    Function to extract the details from the email text files and store in a dictionary\n",
    "    Inputs:\n",
    "        main_dir: the directory containing the email text files\n",
    "    Returns:\n",
    "        email_contents: dictionary containing the extracted dictionaries from the function parse_email().\n",
    "    \"\"\"\n",
    "    line_names = [\"To:\", \"From:\", \"MIME-Version:\", \"Content-Type:\",\n",
    "                 \"Content-Transfer-Encoding:\", \"X-Mailer:\", \"Subject:\",\n",
    "                 \"Precedence:\"]\n",
    "\n",
    "    target_mapping = get_email_target_mappings(main_dir = main_dir)\n",
    "    email_contents = {}\n",
    "    for target in target_mapping:\n",
    "        for file in get_directory_file_listing(target[0]):\n",
    "            email_contents[file.split(\"\\\\\")[-1]] = parse_email(file, line_names, target[1])\n",
    "    print(\"Emails extracted to dictionary\")\n",
    "    return email_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_dataframe(email_dict):\n",
    "    \"\"\"\n",
    "    Function to convert a dictionary to a dataframe and tranpose the resulting dataframe.\n",
    "    Input:\n",
    "        email_dict: a dictionary containing dictionaries with extracted email information\n",
    "    Returns:\n",
    "        df: dataframe generated from the dictionary, transposed to keep keys as the columns and not as the rows.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(email_dict).transpose().reset_index()\n",
    "    print(\"DataFrame generated\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_email_dataframe():\n",
    "    \"\"\"\n",
    "    Wrapper function to return a dataframe from the extracted email archives\n",
    "    \"\"\"\n",
    "    email_dict = extract_email_data_to_dictionary(main_dir = main_dir)\n",
    "    print(\"Base dataframe ready for cleansing\")\n",
    "    return convert_dict_to_dataframe(email_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target directories extracted\n",
      "Target mappings extracted\n",
      ".\\data\\extracted\\20021010_easy_ham\\easy_ham\\\n",
      ".\\data\\extracted\\20021010_hard_ham\\hard_ham\\\n",
      ".\\data\\extracted\\20021010_spam\\spam\\\n",
      "'charmap' codec can't decode byte 0x81 in position 3082: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0123.68e87f8b736959b1ab5c4b5f2ce7484a\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0255.42a6feb4435a0a68929075c0926f085d\n",
      "'charmap' codec can't decode byte 0x81 in position 2588: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0273.51c482172b47ce926021aa7cc2552549\n",
      "'charmap' codec can't decode byte 0x81 in position 2503: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0330.a4df526233e524104c3b3554dd8ab5a8\n",
      "'charmap' codec can't decode byte 0x81 in position 2682: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0334.3e4946e69031f3860ac6de3d3f27aadd\n",
      "'charmap' codec can't decode byte 0x81 in position 2728: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0335.9822e1787fca0741a8501bdef7e8bc79\n",
      ".\\data\\extracted\\20030228_easy_ham\\easy_ham\\\n",
      ".\\data\\extracted\\20030228_easy_ham_2\\easy_ham_2\\\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_easy_ham_2\\easy_ham_2\\00664.28f4cb9fad800d0c7175d3a67e6c6458\n",
      ".\\data\\extracted\\20030228_hard_ham\\hard_ham\\\n",
      ".\\data\\extracted\\20030228_spam\\spam\\\n",
      "'charmap' codec can't decode byte 0x81 in position 3124: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00116.29e39a0064e2714681726ac28ff3fdef\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00245.f129d5e7df2eebd03948bb4f33fa7107\n",
      "'charmap' codec can't decode byte 0x81 in position 2568: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00263.13fc73e09ae15e0023bdb13d0a010f2d\n",
      "'charmap' codec can't decode byte 0x81 in position 2483: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00320.20dcbb5b047b8e2f212ee78267ee27ad\n",
      "'charmap' codec can't decode byte 0x81 in position 2662: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00323.9e36bf05304c99f2133a4c03c49533a9\n",
      "'charmap' codec can't decode byte 0x81 in position 2708: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00324.6f320a8c6b5f8e4bc47d475b3d4e86ef\n",
      "'charmap' codec can't decode byte 0x8f in position 1674: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00500.85b72f09f6778a085dc8b6821965a76f\n",
      ".\\data\\extracted\\20030228_spam_2\\spam_2\\\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\00721.09d243c9c4da88c5f517003d26196aaa\n",
      "'charmap' codec can't decode byte 0x8d in position 3062: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01065.9ecef01b01ca912fa35453196b4dae4c\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01083.a6b3c50be5abf782b585995d2c11176b\n",
      "'charmap' codec can't decode byte 0x90 in position 2832: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01227.04a4f94c7a73b29cb56bf38c7d526116\n",
      "'charmap' codec can't decode byte 0x9d in position 4099: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01376.73e738e4cd8121ce3dfb42d190b193c9\n",
      ".\\data\\extracted\\20050311_spam_2\\spam_2\\\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\00721.09d243c9c4da88c5f517003d26196aaa\n",
      "'charmap' codec can't decode byte 0x8d in position 3062: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01065.9ecef01b01ca912fa35453196b4dae4c\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01083.a6b3c50be5abf782b585995d2c11176b\n",
      "'charmap' codec can't decode byte 0x90 in position 2832: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01227.04a4f94c7a73b29cb56bf38c7d526116\n",
      "'charmap' codec can't decode byte 0x9d in position 4099: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01376.73e738e4cd8121ce3dfb42d190b193c9\n",
      "Emails extracted to dictionary\n",
      "Base dataframe ready for cleansing\n",
      "DataFrame generated\n"
     ]
    }
   ],
   "source": [
    "#dl_and_create_email_records(lib_url, main_dir, sub_dir)\n",
    "base_email_df = generate_base_email_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_email_df.to_parquet(\"base.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_email = pd.read_parquet(\"base.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_email_df = deepcopy(base_email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9350 entries, 0 to 9349\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   index                       9350 non-null   object\n",
      " 1   target                      9331 non-null   object\n",
      " 2   From:                       9329 non-null   object\n",
      " 3   To:                         9006 non-null   object\n",
      " 4   Subject:                    9322 non-null   object\n",
      " 5   MIME-Version:               6208 non-null   object\n",
      " 6   Content-Type:               8052 non-null   object\n",
      " 7   Precedence:                 5304 non-null   object\n",
      " 8   body                        9331 non-null   object\n",
      " 9   X-Mailer:                   3650 non-null   object\n",
      " 10  Content-Transfer-Encoding:  4604 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 803.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cleansed_email_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_remove_colon_from_column_name(df):\n",
    "    \"\"\"\n",
    "    Function to remove the colon from the column headers and force the text to lowercase\n",
    "    Input:\n",
    "        df: the target dataframe\n",
    "    Returns:\n",
    "        df: df with renamed columns\n",
    "    \"\"\"\n",
    "    df.columns = [x.replace(\":\", \"\").lower() for x in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_components_to_features(df, user_types):\n",
    "    \"\"\"\n",
    "    Function to extract components of the to & from columns to new features\n",
    "        fullname: the fullname of the sender that prefixs the email address\n",
    "        email: the full email address contained in '<email_address>'\n",
    "        username: the username from the email address (everything before @)\n",
    "        domain: the domain of the email address (everything after @)\n",
    "    Inputs:\n",
    "        df: the target dataframe\n",
    "        user_types: list of types of user that will be processed i.e. ['to'], ['from'], ['to', 'from']\n",
    "    Returns:\n",
    "        df: df with additional features added.\n",
    "    \"\"\"\n",
    "    for user_type in user_types:\n",
    "        # Split the FROM column into full name, username and domain\n",
    "        # df[str(user_type + '_fullname')] = df[str(user_type)].str.split(\"<\", n = 1).str[0].str.replace('\"', \"\")\n",
    "        df[str(user_type + '_fullname')] = df[str(user_type)].str.extract(r'[$\\s\\\"]?([\\w\\d\\s]*)[\\s\\\"]')[0]\n",
    "\n",
    "        # Extract the from email\n",
    "        # df[str(user_type + '_email')] = df[str(user_type)].str.split(\"<\").str[1].str.replace('>', \"\")\n",
    "        # df[str(user_type + '_email')] = df[str(user_type)].str.extract(r'[\\s<]?([\\w\\d\\+]*@.*\\.[\\w\\d]*)')[0]\n",
    "        df[str(user_type + '_email')] = df[str(user_type)].str.extract(r'([\\w\\d\\+]+@[\\w\\d]+\\.[\\w\\d]+)')[0]\n",
    "        df[str(user_type + '_email_count')] = df[str(user_type)].str.count(r'([\\w\\d\\+]+@[\\w\\d]+\\.[\\w\\d]+)')\n",
    "        \n",
    "        # Extract the from username\n",
    "        df[str(user_type + '_username')] = df[str(user_type + '_email')].str.extract(r'(.*)[@]')\n",
    "\n",
    "        # Extract the from domain\n",
    "        df[str(user_type + '_domain')] = df[str(user_type + '_email')].str.extract(r'[@](.*)')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_invalid_to_from_subject_target_records(df):\n",
    "    \"\"\"\n",
    "    Function to exclude records with invalid target, to, from & subject.\n",
    "    Input:\n",
    "        df: email contents dataframe\n",
    "    Returns:\n",
    "        df: email contents dataframe without invaid target, to, from & subject rows.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df[df['target'].notna()]\n",
    "    df = df[df['to'].notna()]\n",
    "    df = df[df['from'].notna()]\n",
    "    df = df[df['subject'].notna()]\n",
    "    df = df[df['to_email'].notna()]\n",
    "    df = df[df['from_email'].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_type_info_from_content_type_records(df):\n",
    "    \"\"\"\n",
    "    Function to extract format, type, encoding & character set information from the content-type string\n",
    "    Input:\n",
    "        df: email contents dataframe\n",
    "    Returns:\n",
    "        df: email contents dataframe with additional columns for content-type data\n",
    "    \n",
    "    \"\"\"\n",
    "    df['content-type-format'] = df['content-type'].str.lower().str.extract(r'^(\\w+)/')\n",
    "    df['content-type-type'] = df['content-type'].str.lower().str.extract(r'^\\w+/(\\w+)[;\\s]?')\n",
    "    df['content-type-charset'] = df['content-type'].str.lower().str.extract(r'charset[\\s]?=[\\\"]?([\\w\\d-]+)[\\\"\\s]?')\n",
    "    df['content-type-encoding'] = df['content-type'].str.lower().str.extract(r'encoding[\\s]?=[\\\"]?([\\w\\d-]+)[\\\"\\s]?')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try functions\n",
    "cleansed_email_df = deepcopy(base_email_df)\n",
    "cleansed_email_df = rename_columns_remove_colon_from_column_name(cleansed_email_df)\n",
    "cleansed_email_df = extract_email_components_to_features(cleansed_email_df, ['to', 'from'])\n",
    "cleansed_email_df = exclude_invalid_to_from_subject_target_records(cleansed_email_df)\n",
    "cleansed_email_df = extract_content_type_info_from_content_type_records(cleansed_email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop after review\n",
    "# mime-version: no appreciable relevance - all values are 1 with an insignificant qty including additional info (approx 2%)\n",
    "# content-type: feature extraction is complete\n",
    "# Precedence: no appreciable relevance - no alignment between bulk and to_email_count and no obvious way to infer type. Possibly revisit or attempt to create a feature independently\n",
    "# Content-transfer-encoding: Not enough data to add menaingful information - 7 bit appears to have a higher frequency with HAM email.\n",
    "# x-mailer: emails with x-mailer seem more likely to be HAM but this can be explored further in future iterations.\n",
    "\n",
    "dropping = ['mime-version', 'content-type', 'precedence', 'content-transfer-encoding', 'x-mailer']\n",
    "cleansed_email_df.drop(dropping, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8517 entries, 0 to 9349\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  8517 non-null   object \n",
      " 1   target                 8517 non-null   object \n",
      " 2   from                   8517 non-null   object \n",
      " 3   to                     8517 non-null   object \n",
      " 4   subject                8517 non-null   object \n",
      " 5   body                   8517 non-null   object \n",
      " 6   to_fullname            2403 non-null   object \n",
      " 7   to_email               8517 non-null   object \n",
      " 8   to_email_count         8517 non-null   float64\n",
      " 9   to_username            8517 non-null   object \n",
      " 10  to_domain              8517 non-null   object \n",
      " 11  from_fullname          7213 non-null   object \n",
      " 12  from_email             8517 non-null   object \n",
      " 13  from_email_count       8517 non-null   float64\n",
      " 14  from_username          8517 non-null   object \n",
      " 15  from_domain            8517 non-null   object \n",
      " 16  content-type-format    7646 non-null   object \n",
      " 17  content-type-type      7646 non-null   object \n",
      " 18  content-type-charset   5359 non-null   object \n",
      " 19  content-type-encoding  1262 non-null   object \n",
      "dtypes: float64(2), object(18)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cleansed_email_df.info())\n",
    "df = deepcopy(cleansed_email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\\nReferences: <1029945287.4797.TMDA@deepeddy.vircio.com>\\n<1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\\n<1029943066.26919.TMDA@deepeddy.vircio.com>\\n<1029944441.398.TMDA@deepeddy.vircio.com>\\nMIME-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nMessage-Id: <13258.1030015585@munnari.OZ.AU>\\nX-Loop: exmh-workers@example.com\\nSender: exmh-workers-admin@example.com\\nErrors-To: exmh-workers-admin@example.com\\nX-Beenthere: exmh-workers@example.com\\nX-Mailman-Version: 2.0.1\\nPrecedence: bulk\\nList-Help: <mailto:exmh-workers-request@example.com?subject=help>\\nList-Post: <mailto:exmh-workers@example.com>\\nList-Subscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=subscribe>\\nList-Id: Discussion list for EXMH developers <exmh-workers.example.com>\\nList-Unsubscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\\nList-Archive: <https://listman.example.com/mailman/private/exmh-workers/>\\nDate: Thu, 22 Aug 2002 18:26:25 +0700\\n\\nDate:        Wed, 21 Aug 2002 10:54:46 -0500\\nFrom:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\\nMessage-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\\n\\n\\n| I can\\'t reproduce this error.\\n\\nFor me it is very repeatable... (like every time, without fail).\\n\\nThis is the debug log of the pick happening ...\\n\\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\\n18:19:04 Ftoc_PickMsgs {{1 hit}}\\n18:19:04 Marking 1 hits\\n18:19:04 tkerror: syntax error in expression \"int ...\\n\\nNote, if I run the pick command by hand ...\\n\\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\\n1 hit\\n\\nThat\\'s where the \"1 hit\" comes from (obviously).  The version of nmh I\\'m\\nusing is ...\\n\\ndelta$ pick -version\\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\\n\\nAnd the relevant part of my .mh_profile ...\\n\\ndelta$ mhparam pick\\n-seq sel -list\\n\\n\\nSince the pick command works, the sequence (actually, both of them, the\\none that\\'s explicit on the command line, from the search popup, and the\\none that comes from .mh_profile) do get created.\\n\\nkre\\n\\nps: this is still using the version of the code form a day ago, I haven\\'t\\nbeen able to reach the cvs repository today (local routing issue I think).\\n\\n\\n\\n_______________________________________________\\nExmh-workers mailing list\\nExmh-workers@redhat.com\\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words(df):\n",
    "    \"\"\"\n",
    "    Function to encapsulate the process of generating a list of unique words from the body column.\n",
    "    Input:\n",
    "        df: target dataframe\n",
    "    Output:\n",
    "        unique_words: a list of all unique words contained in the body column of the target dataframe df.\n",
    "    \"\"\"\n",
    "    punc_map = str.maketrans(dict.fromkeys(string.punctuation, ''))\n",
    "    df['words'] = df['body'].str.translate(punc_map).str.replace(\"\\n\", \" \").str.replace(\"\\t\", \" \").str.split(\" \")\n",
    "    \n",
    "    unique_words = (list(set([a.strip() for b in df['words'].tolist() for a in b])))\n",
    "    \n",
    "#     all_words = df[['body']].drop_duplicates()\n",
    "#     all_words['split'] = all_words['body'].astype(str).map(lambda x: x.split(\" \"))\n",
    "#     unique_words = (list(set([a.strip() for b in all_words['split'].tolist() for a in b])))\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'iss',\n",
       " 'align3Dleftcenterfont',\n",
       " 'httpbootrecordscom',\n",
       " '2001',\n",
       " 'SIZE25FONT',\n",
       " 'fax20',\n",
       " 'Zope',\n",
       " 'codetoArraycode',\n",
       " 'alt3DImpaired',\n",
       " 'bootptftp',\n",
       " 'JxTK9VZ2Fmf6ExYDt2xNoNH8A0qtWTsRpJfjSzZDIpqnsb4nlONULwkzc8tPQK75oOrKdLK',\n",
       " '153418',\n",
       " 'VEJPRFkPC9UQUJMRT48L0JPRFkPC9IVE1MPg0K',\n",
       " 'srchttpimagessandboxcomimagesemailvistaprintKITAnimatedBCgif',\n",
       " 'Magazineb',\n",
       " 'financierosbr',\n",
       " 'builjmding',\n",
       " 'Apocalypse',\n",
       " 'Botanical',\n",
       " 'ZTxicj4NCiAgICAgIGNvc3RseSBhdHRvcm5leXMgYXJlIGRvaW5nIGV4Y2VwdCBvdXIgY3JlZGl0',\n",
       " 'title20020712',\n",
       " 'colorwhitetdfontfamily',\n",
       " 'Toy',\n",
       " 'sansserifSONGfontbtd',\n",
       " 'color006666Click',\n",
       " 'flourishing',\n",
       " 'QUOTEDEMAILTEXTREFERENCESSPAMPHRASE0203',\n",
       " 'rollover',\n",
       " 'src3Dhttpiiqusimagesaigsetrate20020912101jpg',\n",
       " 'wstlurNa6h1U3Edui5MFpJclds2lWE9AcZBJ4ePWnjVf0po22aQamN25JxKfLpKvFKfhRnoPvVB2',\n",
       " 'value800',\n",
       " 'btheres',\n",
       " 'size3D1Paralysisfontbtd',\n",
       " 'Ramses',\n",
       " 'cobble',\n",
       " 'daystrongfontpbr',\n",
       " 'DynDNSorg',\n",
       " 'srchttpiicomcomcnwk1dAdscommonadvertisementgif',\n",
       " 'src3Dhttpwwwzdnetcomproductsgraph',\n",
       " 'Sega',\n",
       " 'size2brfont',\n",
       " 'Bride',\n",
       " 'finden',\n",
       " 'subjectFONTFONT',\n",
       " 'surpirses',\n",
       " 'Grenada',\n",
       " 'classbtitleINSTANT',\n",
       " 'shoot',\n",
       " 'approvals',\n",
       " 'httpenkelriktatmonkeytoyscom',\n",
       " 'prosperous',\n",
       " 'betas',\n",
       " '2yrold',\n",
       " 'lickthruonlinecomClickq3Da26M7QXZHFzGbK9R0CGkHtsonR',\n",
       " 'Pato',\n",
       " 'hrefhttpclickthruonlinecomClickqabZcQKQYpdiyXIeMcXydit0M0OvrR',\n",
       " 'L2TP',\n",
       " '160255',\n",
       " 'Avayaa',\n",
       " '3619ezfT0011VpTm2924l20',\n",
       " 'af6decorecpp316',\n",
       " '20020925T2251450800',\n",
       " 'src3Dhttp6',\n",
       " 'noncaffeine',\n",
       " 'Envelopeto',\n",
       " 'ALTAdvertisementTDTD',\n",
       " 'bgcolor3D000033',\n",
       " 'Yesterday',\n",
       " 'obligationsBRBRBR',\n",
       " 'hrefhttpicannblogusstories20020729auerbachWinsCourtCriticizehtmlBret',\n",
       " 'wwwaynrandorg',\n",
       " 'filterbased',\n",
       " 'eleven',\n",
       " 'boundaryNextPart000003F01C1E71664A6E300typemultipartalternative',\n",
       " 'hits9056',\n",
       " 'generateBRfrom',\n",
       " 'summarise',\n",
       " 'testsAWLKNOWNMAILINGLISTNOSPAMINCSIGNATURELONGSPARSE',\n",
       " 'httpradioweblogscom0100682',\n",
       " 'SRC3Dhttpaddoubleclicknetad',\n",
       " 'YudelLine',\n",
       " 'H',\n",
       " 'addressee',\n",
       " '080133',\n",
       " '021958',\n",
       " 'border0tdtrtrtd',\n",
       " 'pass',\n",
       " 'hrefhttpclickthruonlinecomClickq8a3y3dQXnM4BqAJjoO3NttKChBwsR',\n",
       " 'b60bnbspnbspimg',\n",
       " 'politicara',\n",
       " 'HREFhttpliststheserversidecomt12337850395212181Read',\n",
       " 'Indianowned',\n",
       " 'BLAKE',\n",
       " 'twitter',\n",
       " 'valuenuNiueoption',\n",
       " 'BxEDfBGnwYMLJhxaBFraIgd4ppMs9h01ebsRpMk6LTG5Z67W9His3q2f5BZvWN6fBBwiQ6YPIr',\n",
       " '3l5UVFTA4XCQZ4Hnz59HZ2cnsrOzSdvw8HC8ffsWY2NjIAiCwonOTxEREWQwVlRUQKfTYXBw',\n",
       " 'valignmiddle',\n",
       " 'notgood',\n",
       " 'basicsbrbr',\n",
       " 'MainActor',\n",
       " 'getterscan',\n",
       " '22773175ALT',\n",
       " 'ReportFONTFONTFONTB',\n",
       " 'curve',\n",
       " '68',\n",
       " 'GBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr2wBDAQcICAoJChQLCxQqHBgcKioqKioq',\n",
       " 'L8FNlSpUqVAy5cuXLlNlSvDf8B4a8df8AnaAAwDAQACEQMRAAAQzBkckkgyvu3XkiUlXcEg',\n",
       " 'microarchitectures',\n",
       " 'width3D50IMG',\n",
       " 'AboutBR',\n",
       " 'VALOUR',\n",
       " 'CONTAINS',\n",
       " 'PenguinCORE',\n",
       " 'Dawson',\n",
       " 'resolutions',\n",
       " 'mailboxBR',\n",
       " '4900spanbfontfonttt',\n",
       " '0p',\n",
       " '180144',\n",
       " 'httpmoonshinecarwreckcom',\n",
       " '22TQ1ePTWFg4eMOU3GtRYFVHBc6VNkPxIsepvS3L1z61XphZRDkVaOXJNXbHXJfRSxU94lgUT',\n",
       " 'chests',\n",
       " 'T87FiFHzNA2sooSaMURKIEQCICFDF3OJZQJCKDx7L2K6JMTcF3YfZciaEXufICFLAFcsE4P8A4O',\n",
       " 'netdbh',\n",
       " 'ufontp',\n",
       " '2AKARcyqKLGowtoyBpJTIG8RdkTcG5CilK60qjsg8OBQAOGEqSAHOQRQ21M6AKAVyOkMDcFgDqUj',\n",
       " 'hrefhttpclickthruonlinecomClickq9etWQoQtMQJGPTPz2HSCN0U7nQUDRR',\n",
       " 'vQJOB7OXqwsXG501thD5nZe8hsUTd3yOPINHVe7fTupaGKJ4aJMapNJyNZOXY8MkqSiIiKr4hIFu',\n",
       " '20020925T1045150500',\n",
       " 'BUILD',\n",
       " 'shutters',\n",
       " 'grab',\n",
       " 'credibilityb',\n",
       " 'shorttempered',\n",
       " 'temperatuers',\n",
       " 'srchttpartvcomcnet1dip06060digidarkjpg',\n",
       " 'c3RzIG9mIHRob3VzYW5kcyAgb2Ygb3RoZXIgZW1haWwgcHJvdmlkZXJzIHBs',\n",
       " 'FA4ODhQUDg4ODhQRDAwMDAwREQwMDAwMDBEMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwM8AA',\n",
       " 'pilotbabr',\n",
       " 'wBSK5lvJmoKnuVMirpVb2XBNKowxVIz5qtjt9sbNjp6v4dvdQwlITvKitQAASNTr3RXsYVy8',\n",
       " 'keipeng',\n",
       " 'Orton146s',\n",
       " 'width504',\n",
       " 'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACuXrMPlf8FhXL1mHyv',\n",
       " 'PC1066',\n",
       " 'missionaries',\n",
       " 'Vuorios',\n",
       " 'Dealers',\n",
       " 'CDBRBRSpecifically',\n",
       " 'srchttpwww9to6ie9to6special2fileslasergifspanaspan',\n",
       " 'GBs',\n",
       " 'httpwwwadclickwspcfmo315spk007',\n",
       " 'Solo',\n",
       " 'httpwwwrubyancompolitics',\n",
       " 'notebooksabbr',\n",
       " 'spamassassindevel',\n",
       " '1320',\n",
       " 'eral',\n",
       " 'geneva',\n",
       " 'Announcementbbr',\n",
       " 'sansserifbGo0D',\n",
       " 'newCapacity',\n",
       " 'href3Dhttpwwwebookinfocomoffnowcfmclick',\n",
       " 'Drunken',\n",
       " 'projectBRBFrothPak',\n",
       " 'size2Want',\n",
       " 'splitting',\n",
       " 'Contacts',\n",
       " 'taps',\n",
       " 'hackersba',\n",
       " 'patronizing',\n",
       " '145918',\n",
       " 'salicicola',\n",
       " '004518',\n",
       " 'bootstrapdiscovery',\n",
       " 'rEAver',\n",
       " 'BRBRTomorrow',\n",
       " 'versendet',\n",
       " 'MARKETER',\n",
       " '181512',\n",
       " 'Absinthium',\n",
       " 'Rod',\n",
       " '4Id3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3d3',\n",
       " 'FONTa',\n",
       " 'rightwingnuts',\n",
       " 'ShagMail',\n",
       " 'higgstracyhotmailcom',\n",
       " 'QuickLinks',\n",
       " 'internal',\n",
       " 'MPAD0V',\n",
       " '1309',\n",
       " 'Poles',\n",
       " 'width1TDTRTBODYTABLEFONT',\n",
       " 'telle',\n",
       " 'Redefining',\n",
       " '18z4TEREREVXxAcW6HXUnTPsRq0VNxR5yy2snpDomilBbLt81kFpecsdsA4k7LnW3K4U3DtZW0',\n",
       " 'journeys',\n",
       " 'httpwwwcs220commortgageremovehtml',\n",
       " 'height823',\n",
       " 'resaon',\n",
       " 'mismatch',\n",
       " 'VxBg8x54N6qsuHuHaThqhdSUcs8jXvMjnTP1EuPM9w9itkREREVRXS4v9K0SBvYU0sr9Q6HSBv0',\n",
       " 'IDYoQ6UBDOR0kBQFA66V09Y9CfekAcsPBziA3VuXsun4wb9fBZA4NpC3QJgkJht0gMLAwxq5QA',\n",
       " 'Assam',\n",
       " 'color3DFFFFFFNEW',\n",
       " '627',\n",
       " 'Vincentoption',\n",
       " 'Heighten',\n",
       " 'freedomloving',\n",
       " 'httpcorkynetdotanlog',\n",
       " 'oil',\n",
       " 'foothair',\n",
       " 'bug',\n",
       " 'wanted',\n",
       " 'Sending',\n",
       " 'adversary',\n",
       " 'bate',\n",
       " 'httpwwwnewsisfreecomclick382518671440',\n",
       " 'href3Dhttp6115124739erikinkjets',\n",
       " 'US36000000',\n",
       " 'ZXMgaGFzIGJlZW4gZG9uZSB0byB0aGUgYmVzdCBvZiBvdXIgYWJpbGl0eSwg',\n",
       " 'podrzao',\n",
       " 'gnome2s',\n",
       " 'per20',\n",
       " 'spiderman',\n",
       " 'searchQuery',\n",
       " 'affiliés',\n",
       " 'IGFuZCBlYXN5LXRvLXJlbWVtYmVyIGRvbWFpbiBuYW1lIGZvciB0aGUgc2Ft',\n",
       " '012PC',\n",
       " 'csse',\n",
       " '90069',\n",
       " 'bmU6c1ne9cXuKsWp5J2EIQHe9cIvYZtUoJdcJIaNPpptK62d1wO98ZnM6mN5UNm2r4cpe7ptNr',\n",
       " 'hrefhttpclickthruonlinecomClickqc93OZLQpgkBHpoGWAjg0SxiPZvH6lR',\n",
       " '28x',\n",
       " 'hrefhttpclickthruonlinecomClickq0313t3I3rzzA30otZhKQcaLlAI6OrR',\n",
       " 'TNONSENSEFROM99100TQUOTEDEMAILTEXT',\n",
       " 'pecuniary',\n",
       " 'cpuld',\n",
       " '617464684646947976726441619467684696468416837196716976687font',\n",
       " 'davehnetnovationscom',\n",
       " 'Including',\n",
       " 'QWVKQTDNUEBESKdJCqLWgGEEDsAEb0aLg6OTdtkbVWeVKL2JLqiAXDzrJ53SqVGDN3KCRgQms',\n",
       " '8mtZQXIOKgHYUFIIKPkPFNOrEIarsTueDCV83XitiN4OJLaROm8BhOpyAwYCeeFOrgItErt8y3Ds',\n",
       " 'valuebuBurmaoption',\n",
       " 'nbspFor',\n",
       " 'width3D78',\n",
       " '20021009T0315160100',\n",
       " 'hrefhttpwwwattorneyconnectionsinccomregistrationhtm',\n",
       " 'WINDOWS',\n",
       " 'cb2000s',\n",
       " 'Maria',\n",
       " 'src3Dhttphomecnetcominedsdhedgif',\n",
       " 'mailtosamtregarcom',\n",
       " 'CURRENTLY',\n",
       " 'href3Dhttpwwwclreacomfwhyusfinancecfmclass3D1',\n",
       " 'PolicyA',\n",
       " 'Cashtitle',\n",
       " 'bah',\n",
       " 'Imap',\n",
       " 'saddam',\n",
       " 'DEFENSE',\n",
       " 'Stevens',\n",
       " 'height52EM§Ú\\xadn¶R',\n",
       " 'GarGnome',\n",
       " 'invalidates',\n",
       " 'recursos20',\n",
       " 'IqMBceBRM7cxZ1eSE6zGdmZ4GmtUEoxVfBSQAazEARs0Iw4RJxnAMr2BADdRHAHTFRvxGTDXfkcE',\n",
       " 'DISCUSS',\n",
       " 'ospt75',\n",
       " 'sndcardslimit1',\n",
       " 'kitbabr',\n",
       " 'width3D415',\n",
       " 'M61DET6SQCSS9B8CYB',\n",
       " 'kwaveflashembedobjecttd',\n",
       " 'Forzzzzget',\n",
       " 'mailtolisaperlorg',\n",
       " 'classmaintrtd',\n",
       " 'extrasInittcl',\n",
       " 'hrefhttpclickthruonlinecomClickq08IFoQIRjTZeP4nmGg3FerCpGY9iR',\n",
       " 'size3D1Copyright',\n",
       " 'dkZWXx9u1bSktLKS8vp7W1dZRdu92OQqHg5s2bzJ49m7lz5wpPgSfb41lcHAQg8FAREQE',\n",
       " '124904',\n",
       " '023227',\n",
       " 'semiconductor',\n",
       " 'discussionsaulfontp',\n",
       " 'System',\n",
       " 'sDhudpUCSSEEqQNy4jniCFUJkAVeQAESqZMRF1WEk4svwJMPWQAYlTTkpkawZmoBp3wiKDVmaAL',\n",
       " 'httpwwwquicktopiccom16HkymC9LzuB2bHM',\n",
       " 'evolvable',\n",
       " 'listnext',\n",
       " 'classification',\n",
       " '165910',\n",
       " 'ProMedia',\n",
       " 'Gage',\n",
       " 'SDSL',\n",
       " 'youfontcenter',\n",
       " 'Sharps',\n",
       " 'NOS',\n",
       " 'definitively',\n",
       " 'face3DC',\n",
       " 'href3DhttpclickthruonlinecomClickq3D73Z',\n",
       " 'lobjet',\n",
       " 'soundbitten',\n",
       " 'Dk7ceHEqSbBQxlfHVq5cydP1cZVpT6qGtNyY9Tdr4d29gxePpb1iUZ95yawmwXkpLSQca',\n",
       " '32K',\n",
       " 'charset3Diso88591',\n",
       " 'antennas',\n",
       " 'DAV32YiMCIqtQvAauNj00001886hotmailcom',\n",
       " 'httpmediawhoresonlinewatchblogspotcom',\n",
       " 'lookup',\n",
       " 'height3D15nbsptdtr',\n",
       " 'color3Dffff0020',\n",
       " 'youfontbp',\n",
       " '8PDwgLDz8z8MzMzPz88',\n",
       " 'bOnly',\n",
       " 'size3D2nbsppyzor',\n",
       " 'hrefhttpclickthruonlinecomClickqa5DyaHQ7ZTGfhxrbzsIC1b2OB8OEPR',\n",
       " 'videoconferencing',\n",
       " 'name3Dmainr5c2',\n",
       " 'sidetracked',\n",
       " 'cheapo',\n",
       " 'IBUThousands',\n",
       " 'id3DINCREDIFOOTER',\n",
       " 'retell',\n",
       " 'pages',\n",
       " 'style3Dlineheight',\n",
       " 'continuity',\n",
       " 'County',\n",
       " 'httpclickthruonlinecomClickq11l8riI24EmyuBjX3VynhNBuCqlR',\n",
       " 'Hotspots',\n",
       " 'wrestling',\n",
       " 'Willing',\n",
       " 'mailtofourAEOpublishingcom',\n",
       " 'osaame2001yahoocom',\n",
       " '4852',\n",
       " 'iIiIvRzIiIiIiIiIiIiIiIiIiIiIo9BkmyNPzTdu7YKQiIiIvSzIiIiIiIiIiIiIiIiIi',\n",
       " '3737FF',\n",
       " 'Tonic',\n",
       " 'closebr',\n",
       " 'is',\n",
       " 'chinaniconlinecomsavequote',\n",
       " 'lFX6OiTEQyokw50Wbmw6C80vP9ARhPOUbXBTXUJ1TlAbrVYkhKZhiikCcAB8MDfKckMA2ABmcBP',\n",
       " 'size3D2Continuous',\n",
       " 'hrefhttpclickthruonlinecomClickq69CYiIoWgaOiklWFMoAH4OpRzLxFR',\n",
       " 'AmphetaDesk4',\n",
       " 'Ryan',\n",
       " 'senegalwhich',\n",
       " 'Ojxicj48YnIDQombmJzcDsmbmJzcDsmbmJzcDs8Rk9OVCBjb2xvcj0jMDAw',\n",
       " 'MhDistSetup',\n",
       " 'srchttpwwwcuteftpcomscriptspvasppid11',\n",
       " 'astonishing',\n",
       " 'interject',\n",
       " 'inject',\n",
       " '3D6fontBRBRfont',\n",
       " 'Copyright1692002',\n",
       " 'SUPPLIESBR',\n",
       " 'E17cz4E0008A600cpu59osdncom',\n",
       " 'dass',\n",
       " 'CHRISTOPHER',\n",
       " 'Overreaching',\n",
       " 'GJgI8XwXJJiPH0CLlcgAFAiJBNgAggoXIrGdDfI7mdKK5CMeG1GSXtOdXuiO5saTcwMNgTMN8VU',\n",
       " 'tonne',\n",
       " 'discountnbsp',\n",
       " 'color848383',\n",
       " 'IfJRxOOQpcEbgTfmwsfJRxMRu2l9k2MfUsJVxOSRopMHb9m6e5YSniY4zHS7DO8wI9XJD5KOJh',\n",
       " 'positives',\n",
       " 'AmoBameR',\n",
       " 'blueprints',\n",
       " 'httpwwwaskbjoernhansencomarchives20020926html',\n",
       " 'httpGBlognetusertHatgrLkarLa',\n",
       " 'leastu',\n",
       " 'speed',\n",
       " 'Stampu',\n",
       " '\\x1bB27F\\x1bB',\n",
       " 'capacitor',\n",
       " 'greatful',\n",
       " 'srchttpwwwcnetcomishnlcomponents03giftd',\n",
       " 'face3DAriala',\n",
       " '66315282',\n",
       " 'ICAgICAgICAgICAgIG11bHRpcGxleGVyIGRpc3BsYXkgbW9kZXM8L2ZvbnQPC9iPjwvdGQDQog',\n",
       " 'Embedded',\n",
       " 'Headlamp',\n",
       " '2fontfontbblockquote',\n",
       " 'strongspanspan',\n",
       " 'mailtolvirdencasorg',\n",
       " 'Kennedy',\n",
       " 'DFW',\n",
       " 'CLASSFEATURES',\n",
       " 'interviewsfontbfont',\n",
       " 'testsAWLINVALIDMSGIDKNOWNMAILINGLISTQUOTEDEMAILTEXT',\n",
       " 'Best20',\n",
       " 'Faster',\n",
       " 'background3Dimagesfonwhitegiftrtd',\n",
       " 'Green',\n",
       " 'minions',\n",
       " 'CHAIR',\n",
       " '10pt±×·³',\n",
       " 'allconsuming',\n",
       " 'bathhouse',\n",
       " 'unrelated',\n",
       " 'ially',\n",
       " 'bLDAP',\n",
       " 'HREFhttponlinewsjcomarticle0SB102889868127962508000htmlhttponlinewsjcomarticle0SB102889868127962508000htmlA',\n",
       " '11551520',\n",
       " 'check26155',\n",
       " '234953',\n",
       " 'CHARITABLE',\n",
       " 'hrefhttpwwwrequestedinfonetcgibinrbiscgicodebt5bt5font',\n",
       " 'hrefProfitBannerscom',\n",
       " '192406',\n",
       " 'WIDTH319',\n",
       " 'dgsbtinternetcom',\n",
       " 'ArialVerdanaHelveticaLIFONT',\n",
       " '0217',\n",
       " 'httpwwwdrollerycomindexphp',\n",
       " 'hex',\n",
       " 'hrefhttpclickthruonlinecomClickq145MRAIFzaBLVZ98ZvQIzTKtR1dR',\n",
       " 'Tuba',\n",
       " 'daytoday',\n",
       " 'Studiesfonttd',\n",
       " 'httpsurftoloverso',\n",
       " 'vacuous',\n",
       " 'b2RheSBmb3IgbW9yZSBpbmZvLg0KIA0KUmVnaXN0ZXIgeW91ciBkb21haW4g',\n",
       " 'color0000FFRates',\n",
       " 'Here3C2Fb3E3C2Ffont3E3C2Fa3E3Cbr3E',\n",
       " 'color666666This',\n",
       " '20021004102537C22111canarsiehorizonlivecom',\n",
       " 'instantaneous',\n",
       " 'width127bfont',\n",
       " 'src3D22httpimgdefeasyadpostcomaddefem01gif22',\n",
       " 'Oyi4vEk18TsYSl6KbA3OxEHWnF4awwk28LmBwEpQlFZlFpERLsASjGUvRTfwIjYA7GLk8RTfwDW',\n",
       " 'Raul',\n",
       " 'hrefhttpwwwimakenewscomeletraremovecfmxmediaunspun2CzzzzunspunspamassassintaintorgREMOVEa',\n",
       " 'ConAgra',\n",
       " 'Mittwoch',\n",
       " 'LIUL',\n",
       " 'millionaire',\n",
       " 'MySql',\n",
       " '296819lightwatchaspclick',\n",
       " 'NandoTimes',\n",
       " 'hrefhttpclickthruonlinecomClickq59y5OozjnNuCiDwN4UQzUlGf6dM7xysRRUnsubscribeanbsp',\n",
       " 'invariably',\n",
       " 'innumeracy',\n",
       " 'boneheads',\n",
       " 'BaeoLastAuthor',\n",
       " 'trainning',\n",
       " 'color3D8182ABp',\n",
       " 'httpwwwnewsisfreecomclick580625381440',\n",
       " 'boundaryNextPart00000B283B03D1EC6530E24',\n",
       " 'QbmPZrUrasVHctTGKaY7rAOZ4u7WayhsVeKVSjl2r19sVef33mW5aAQQRtaxItONuprAMIM',\n",
       " 'IElNN4TJFEXtmW5AkQtWYEskbZebjqAp9EmRqWIEgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA',\n",
       " 'gfooterpdf',\n",
       " 'NdUx1vahT4AGehX2Eht73oAUJH9TtrJbWuDIBuqyfQ31X1P42YO7zhthQrPhDwKTb7uVsrLO',\n",
       " 'msolisttypehybrid',\n",
       " '200207261237364f34e7felbedfordnetnoteinccom',\n",
       " 'knowI',\n",
       " 'hrefhttppluginaccesscomwedogtypeexeCLICK',\n",
       " '3D000000',\n",
       " 'Agonizing',\n",
       " '1033046883239574',\n",
       " 'PIONEER',\n",
       " '2002073014285332654qmaillinuxmailorg',\n",
       " 'IGFkZHJlc3MgdG8gam9pbjwvYT4hDQo8YnIPGJyPjxicj4NCjxmb250IGZh',\n",
       " 'altillustr3',\n",
       " 'a22481297401040sectionheadingcolorFFFFFFbackgroundcolor000000fontfamilyarialfontsizexsmallfontweightboldfontstylenormaltextdecorationnonetextalignleft',\n",
       " 'face3DArialExfont',\n",
       " 'Diabetesbr',\n",
       " 'explorers',\n",
       " 'ftocimplied',\n",
       " 'ICAgICAgICAgPGJyPg0KICAgICAgICA8YnIDQogICAgICAgIDxiPg0KICAgICAgICBNb3RpdmF0',\n",
       " 'Regression',\n",
       " 'hrefABRBODYHTML',\n",
       " 'TNONSENSEFROM0010USERAGENTUSERAGENTMUTT',\n",
       " 'Zealot',\n",
       " 'Intergovernmental',\n",
       " 'areastfontfamily',\n",
       " 'thanstrongfont',\n",
       " 'UIcAVABXAAFPQAU1cAAZAAGgMAYnwAVjAAyhMGfGciyJVgCksAehsAiMIAx5UAtlIAMzIHmtEAMg',\n",
       " 'skiph',\n",
       " '303',\n",
       " 'tombs',\n",
       " 'httpwwwgaryarnoldcomprojectsphpbayespam',\n",
       " 'businesscentric',\n",
       " 'httphomeearthlinknetpmurray63',\n",
       " 'g89A4HE9013144',\n",
       " 'collides',\n",
       " 'bgcolore2e2e2font',\n",
       " '5Mi5S89NgCA4VsgEEMzlOoAh9YnNCY3JPCXoYCbDDZAoD5hAIAKkgimUZlm6wCqKmWpXFAHAFH5',\n",
       " 'wad',\n",
       " 'specs',\n",
       " 'Plaza',\n",
       " 'httpummail4unitedmediacom80Clickq3D50M6BIR0rsFWQArVAS5nxjtaOIRRR',\n",
       " 'HEIGHT106TD',\n",
       " 'crypto',\n",
       " 'NextPart0001F32E901C1F449C9876C50',\n",
       " '5EuGsulZw5R1DnTdsUt7SEGQvj0khzmsxjkBz9uFpbJKyzXKamZLBWGoia8Ru0HX2UbnEk573b',\n",
       " 'mhPrivpubseqfamilycur',\n",
       " 'NA',\n",
       " 'C4127X',\n",
       " 'httpjeremyzawodnycomblogarchives000202html',\n",
       " 'knowpp',\n",
       " 'ESTABLISHEDRELATED',\n",
       " 'harmless',\n",
       " 'h3D60',\n",
       " 'BNYSE',\n",
       " 'HEIGHT525',\n",
       " 'style3DBACKGROUNDCOL',\n",
       " 'http1products',\n",
       " 'popular20',\n",
       " 'nilla',\n",
       " 'httpwwwnewsisfreecomImagesfarkiolgif',\n",
       " 'srchttpwwwprintpalnetimagesmail4bgif',\n",
       " 'httpwwwhotmailcom',\n",
       " 'srchttptechupdatezdnetcomtechupdateitulschlesingergif',\n",
       " 'business20',\n",
       " 'Freakatorium',\n",
       " 'Cryptonomicon',\n",
       " 'R93B6872PCQ65AET6SQCT65AYL8S',\n",
       " 'JUDGMENTs',\n",
       " 'Nb',\n",
       " 'InsuranceA',\n",
       " 'aXIuIEF5cmljYSBzaW5pcnNpeiANCnZlIHRvcGx1IHNtcyBn9m5kZXJlYmlsaXJzaW5pei4g',\n",
       " 'classsmallCopyright',\n",
       " 'Errorsb',\n",
       " 'evaltarglocation3DselObjoptionsselObjselectedIndexvalue',\n",
       " 'parties',\n",
       " 'wDisplayHorizontalDrawingGridEvery0wDisplayHorizontalDrawingGridEvery',\n",
       " 'completes',\n",
       " 'Associ',\n",
       " 'width3D12img',\n",
       " 'Meyer',\n",
       " 'IHNpdGVzLjxicj4NCiZuYnNwO0lmIHlvdSBkbyBub3Qgd2FudCB0byByZWNl',\n",
       " 'testsFORGEDRCVDTRAILKNOWNMAILINGLISTSIGNATURELONGSPARSE',\n",
       " 'reportbottom',\n",
       " 'Detection',\n",
       " 'resolves',\n",
       " 'kZ28PB9bgi4cHr7W6TiR',\n",
       " 'broker',\n",
       " 'color3DFF0000font',\n",
       " '±Ù¹«ÇÒ',\n",
       " 'Marcinkiewicz',\n",
       " 'uLNKT6ZacDJmMWZECK1pQiVfAiyg7wJYRKC0RqAKqH2sJ3jA1SmHpxUxY754TJ3KelRTqiucbB3R',\n",
       " 'Excuse',\n",
       " 'xjrpBpGFOWD53WcNIum9jHtZFBFTsW5uZK1M5dVacYxXWLhQaflKOM5U1HSlZUSlsDcu4HVIl0u',\n",
       " 'halos',\n",
       " '53051031637136munnariOZAU',\n",
       " 'sell',\n",
       " 'httpretardedaznbishcomindexphp',\n",
       " 'size3D2Call',\n",
       " 'Hunts',\n",
       " 'sansserifbYESb',\n",
       " 'Even20',\n",
       " 'apg1213fr1rootpython',\n",
       " 'fasterSPANFONTBOPOP',\n",
       " 'guessing',\n",
       " 'monthly',\n",
       " 'orderingfontfont',\n",
       " 'textalign',\n",
       " 'bFfpehTypHG1dBTvAWfqEaPdRUCVhmLlb68FAePcO6Vn84UzVmSH47pfMhYBVZgHLQ6XrSYm6',\n",
       " 'size3D2StateFONT',\n",
       " 'kizU0dvjztuCrSWVKbjDdmXUnrJWKCUFwaeWaHK792WtdnOzbZ5qWM9R2C7o7XJ56EacOMlKLaw',\n",
       " 'formfonttdtd',\n",
       " 'gpgPubkeyMods',\n",
       " '043044',\n",
       " 'father',\n",
       " 'spammedalotcommonwealthcom',\n",
       " 'spanfont',\n",
       " 'blondeshell',\n",
       " 'PFormer',\n",
       " 'hrefhttpclickthruonlinecomClickq2eeMTGIiKj5MjbWxktQ3DlPfP8N4R',\n",
       " 'basking',\n",
       " 'hrefhttp6623113363indexhtmlIDb32Rates',\n",
       " 'SRChttpclickthruonlinecomClickq81z1KaxKW8d4uEJI79st9QKU9RR',\n",
       " 'ZHMsIHByb3ZpZGUgZnVuZHMgZm9yIGV4cGFuc2lvbiBhbmQgb3RoZXIgbmVl',\n",
       " 'McCain',\n",
       " 'Content',\n",
       " '¿¹»ÚÀåÇÑ',\n",
       " 'IDx0ZCBhbGlnbj0icmlnaHQiIGJvcmRlckNvbG9yTGlnaHQ9IiM4MDgwODAiIGhlaWdodD0iMSIg',\n",
       " 'pag',\n",
       " 'color3DCC3333Namefonttd',\n",
       " 'fourteen',\n",
       " 'chalk',\n",
       " 'hrefhttpclickthruonlinecomClickq7bprTIBZIOsmhmhLbDr4q1O7VpJcR',\n",
       " 'Henry',\n",
       " 'Akimbo',\n",
       " '044840',\n",
       " 'Grateful',\n",
       " 'size3D1Phone1',\n",
       " 'C4',\n",
       " 'technophile',\n",
       " 'border0tdtr',\n",
       " 'tingmarketcombclistasp',\n",
       " '20020813',\n",
       " 'sites14',\n",
       " 'size1Whatever',\n",
       " 'deductionFONTTDTRTRTD',\n",
       " 'HREFa97667',\n",
       " 'ActiveSpam',\n",
       " 'hrefhttpnetmusiccountdowncomnewsarticlephpid1w27ti',\n",
       " 'alt3Dtdtd',\n",
       " '25yearold',\n",
       " 'Null',\n",
       " 'sansserifbNObfonttd',\n",
       " '200209121922MAA07568maltesecat',\n",
       " 'height3D218p',\n",
       " 'disparaging',\n",
       " 'iHId4If4j4eIiIiIiIiH8IiIiIiIiAAAAAAIiIiAiIiIiIiIiIiIiIiIiIiIiIeAiIiIiIiIiI',\n",
       " 'Welchs',\n",
       " 'kinds20',\n",
       " 'httpexistentialmoocomquizblog',\n",
       " 'Halifax',\n",
       " 'Dialer',\n",
       " 'harsh',\n",
       " 'Espoon',\n",
       " 'customersfontabr',\n",
       " 'VARY',\n",
       " 'Stevenson',\n",
       " 'XEmacs212',\n",
       " '2995p',\n",
       " 'adolescent',\n",
       " 'hrefhttprmb00netsc1dx2k5015gdafsi52',\n",
       " 'PSI5NSUiIGJnQ29sb3I9I2ZmZmZmZiBib3JkZXI9MD4NCiAgICAgICAgICAg',\n",
       " 'Y3VyZXByby5jb20uaGsiPjxmb250IGNvbG9yPSIjRkZGRkZGIj5pbmZvQHNlY3VyZXByby5jb20u',\n",
       " 'ZipPostal',\n",
       " 'href3Dhttpwwwpayless4inkcomClick',\n",
       " 'Panel3',\n",
       " 'width184img',\n",
       " 'dWUnPjwhW2lmICFzdXBwb3J0RW1wdHlQYXJhc10Jm5ic3A7PCFbZW5kaWZdPjxvOnAPC9v',\n",
       " '4L',\n",
       " 'httpwwwmeikelcom',\n",
       " 'BGCOLORFFFF00',\n",
       " '60GB',\n",
       " 'PPP8v4IiIiIiIh3j4h3j4h3w',\n",
       " 'width100BRIMG',\n",
       " 'iIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIf4iIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiI',\n",
       " 'cv2ZXFwgOz6QA5R7AYdAAgwQBIcTNjGgDFZwA8QHvzABisCBGwQAGYAhfj2fEowAx9ABndgAGRx',\n",
       " 'httpwwwthetrenchcoatcom',\n",
       " 'benign',\n",
       " 'ImmediatelyClick',\n",
       " '75MB',\n",
       " 'contentiMakeNews',\n",
       " 'Spamcon',\n",
       " '062215',\n",
       " 'hrefhttpclickthruonlinecomClickq6de8plIDEI0tYv2AN7Bc1bJBykEmZR',\n",
       " 'l20',\n",
       " 'Humborg',\n",
       " '3737FFfont',\n",
       " 'so…',\n",
       " 'depress',\n",
       " '1500000',\n",
       " '102933716251676camelwintermutesrunhedu',\n",
       " 'fregn',\n",
       " 'httpphorumorg',\n",
       " 'dovenetnovationscom',\n",
       " 'leeches',\n",
       " 'COLOR0000FF',\n",
       " 'bordercolor3D660000',\n",
       " 'dgwlistsbirchesorg',\n",
       " 'foodstuffs',\n",
       " 'LEBAUPIN',\n",
       " 'reviewbanbsp124nbspa',\n",
       " 'bBrandb',\n",
       " 'httpbootrecordscomindexphp',\n",
       " 'httpwwwjoshharveycomindexphp',\n",
       " 'pMsoAutoSig',\n",
       " 'colorredPersonal',\n",
       " 'Bitter',\n",
       " 'slot',\n",
       " 'hrefhttpwwwemmarketcomdelphptablenamea1119813',\n",
       " 'memorial',\n",
       " '550MHz',\n",
       " 'XSluidl',\n",
       " 'inequality',\n",
       " 'captains',\n",
       " 'value3DEastern',\n",
       " 'httpwwwmadworldorg',\n",
       " 'DOWNSIDE',\n",
       " 'Administrativaiquest20',\n",
       " 'httpwww8128org',\n",
       " 'performanceBFONT',\n",
       " 'Dedicated',\n",
       " 'srchttpshoppercnetcomicops12077670191201gif',\n",
       " 'Shippingli',\n",
       " 'color0099333125fontfonttdtr',\n",
       " 'Dutch',\n",
       " 'testsCLICKBELOWFREETRIALHTML5070HTMLFONTCOLORBLUE',\n",
       " 'bHow',\n",
       " 'partioning',\n",
       " 'DilbertATD',\n",
       " '1027203479535414camelathena',\n",
       " 'Jerking',\n",
       " 'hrefhttpwwwGSSGeomaticscomhttpwwwGSSGeomaticscoma',\n",
       " 'H3835',\n",
       " 'Mondou',\n",
       " 'testsAWLINCREASESOMETHINGTNONSENSEFROM4050',\n",
       " 'AIhLzfSxzNzoWaPjrpm8RPzPRPO8nbvaJLL83HFnoky7GbXtulVxWZTeEZrtRBad6dKW6PDOPE',\n",
       " 'bethics',\n",
       " 'Spud',\n",
       " 'tissues',\n",
       " '051040',\n",
       " 'href3DhttpwwwfreehostchinacomYangtzepleasurexNOWabrb',\n",
       " 'jpeg',\n",
       " 'seriesabr',\n",
       " 'hrefhttpclickthruonlinecomClickq18WhdzI98qUUmhwD7TiMEyR1N6759R',\n",
       " 'TLA',\n",
       " '£160000',\n",
       " 'TG0BK5NKIYs5',\n",
       " 'Tub',\n",
       " 'httprobertdsnapsblogspotcom',\n",
       " 'diplomas',\n",
       " 'C7E2BCF6',\n",
       " 'nicotine',\n",
       " 'FA',\n",
       " 'ep4',\n",
       " 'v124',\n",
       " 'background3Dhttpwwwciscocomaucomvpsgtccdadisplayimage0IMG',\n",
       " 'width3D109AP',\n",
       " 'unsub7552100335mm53com',\n",
       " 'continueb',\n",
       " 'PORT',\n",
       " 'hrefhttpclickmm53comsptplid34307552100',\n",
       " 'FONTPtd',\n",
       " 'httpwwwbusinessweekcombwdailydnflashaug2002nf200208130067htm',\n",
       " 'TECHNIQUES',\n",
       " 'gHirK7DMAYxzAAAa1Q0aEBTdBeLpAEP0AGi7sCFFhvceAyTcC5GsE9tUGErAM1ShoFzlkzJEC',\n",
       " 'chilled',\n",
       " 'Optionspy',\n",
       " 'httpsziffdavisomedacomzmmswmswcgiintro2p5UCXA00075',\n",
       " 'Payfonttd',\n",
       " '1670',\n",
       " 'ASCII',\n",
       " '15bfont',\n",
       " 'waiyip',\n",
       " 'tablet',\n",
       " 'broader',\n",
       " 'height3D235fon',\n",
       " 'partyPresently',\n",
       " 'communicate',\n",
       " 'knownbspB',\n",
       " '0nbsptd',\n",
       " 'XFSILOCKSHARE',\n",
       " 'boundaryNextPart0007520601C230D532E68290',\n",
       " 'CONTENTBBEdit',\n",
       " 'httpwwwpolitechbotcomdonate',\n",
       " 'Minutes',\n",
       " 'Aids',\n",
       " 'automaticallyBR',\n",
       " 'LloydRees',\n",
       " 'dhpru0rjUlKMlDg2iMlarVU9V50lwWwU3OzTqFOYzjFec1wIXytrcbbFS2uCfEvyIOqWzzzzoxuadj',\n",
       " 'day',\n",
       " 'Y8P',\n",
       " 'Earning',\n",
       " 'bi5iZXlvbmRpbWVuc2lvbi5jb20vb25lY3VzdG9tZXIvZW1haWwvbGluay5hc3AY2lkPSZhbXA7',\n",
       " 'size3D2226',\n",
       " 'srchttpa772gakamainet777251fa075b8742884bwwwapplecomenews200207images26qh3gif',\n",
       " 'extaordinarily',\n",
       " 'Discounted',\n",
       " 'httpuseperlorgcommentsplsid0207300317236',\n",
       " 'bgcolor3DEEE8F6250000td',\n",
       " 'whirligigs',\n",
       " 'link3D0000ff',\n",
       " 'src3Dhttpwwwworldwebconnectcomimagesvisaetcgif',\n",
       " 'RIAAbacked',\n",
       " 'darken',\n",
       " 'color3D333333We',\n",
       " 'LOLOLOL',\n",
       " 'href3Dhttp20916318754Let',\n",
       " '20020925T2311070100',\n",
       " 'size3D520fontispanfont',\n",
       " 'testsINREPTOKNOWNMAILINGLISTNOSPAMINCOUTLOOKFWMSG',\n",
       " 'OConan',\n",
       " 'tuberculosis',\n",
       " 'width3D143',\n",
       " 'contrary',\n",
       " 'XFace',\n",
       " 'Eugene',\n",
       " 'biew',\n",
       " '852148051BR',\n",
       " 'whatsisname',\n",
       " 'wizard',\n",
       " 'Rim',\n",
       " 'Prados',\n",
       " 'ox3gif',\n",
       " 'reached',\n",
       " 'surplus',\n",
       " 'goAKANNV2KqgxQAyU4Cj1NNCZA8gxtAyT2pgXtIs3Z8sPlA60JCbOgijSMALoqhEbsDIeRTEWo',\n",
       " '20020918112139GA740wwwNTNETWORK',\n",
       " 'altDVD',\n",
       " 'BRmuch',\n",
       " 'commemorated',\n",
       " 'IMPULSE',\n",
       " 'NextPart000010B01C23C66BD4B88D0',\n",
       " 'research20',\n",
       " 'reestablishthe',\n",
       " 'ZSBXb3JsZCdzIGZpcnN0IEFCU09MVVRFTFkgRlJFRSBhZHVsdCBzdXBlcnNp',\n",
       " 'DROPPRIVSyes',\n",
       " 'class3DThmFgTitleLightBk',\n",
       " 'breathe',\n",
       " 'httpwwweamonncom',\n",
       " 'intvalidcnt',\n",
       " 'behalf',\n",
       " 'Relevant',\n",
       " '201522',\n",
       " 'IG9mZmVuc2l2ZS4gWW91IHdpbGwgYWxzbw0Kbm90IGhvbGQgdXMgbGlhYmxl',\n",
       " 'iIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIAP8A',\n",
       " 'AARDVARKPREZENTs',\n",
       " 'Winamps',\n",
       " 'brochureware',\n",
       " 'httpwwwadclickwspcfmo283spk007',\n",
       " 'victorious',\n",
       " 'sparkLingreentea',\n",
       " 'inflated',\n",
       " 'COKER',\n",
       " 'Japanabr',\n",
       " 'entertainment',\n",
       " 'height3D136',\n",
       " 'tmdasendmail',\n",
       " 'sFONTLIF',\n",
       " 'ZlkWZ1JvscssOLozfere4CSxmP29PG4pxBVnltftTyHrOKu6C9O7XxRNVkRENLZMKooGORyL',\n",
       " 'height3D27FONT',\n",
       " 'S750abr',\n",
       " 'FACE3DArialbr',\n",
       " 'httpradioweblogscom0107677categoriesdevelopmentTools',\n",
       " 'MayOPTION',\n",
       " 'sortlynx',\n",
       " 'combustion',\n",
       " 'monument',\n",
       " 'httpwwwhumorisdeadcom',\n",
       " 'Opinions',\n",
       " 'bIntels',\n",
       " 'href3DhttpclickthruonlinecomClickq3D2aCNuWIr',\n",
       " 'Spending',\n",
       " '15914',\n",
       " 'width3D3TD',\n",
       " 'tricks',\n",
       " 'Westminster',\n",
       " 'hrefhttpclickthruonlinecomClickq65K82zIDPtIgFj7K6D70VOf0m8P9ZR',\n",
       " 'kevindated10274802895c6047iesubericnet',\n",
       " 'straining',\n",
       " 'JTsewGMioJkQhOAADpt5AxrmO7TavAQgmIE2fF6D2n46yn2UgMuFKzfpJtOGHCe9AQAmWxyUHO',\n",
       " 'trickle',\n",
       " 'hatching',\n",
       " 'Dealer',\n",
       " 'reservation',\n",
       " 'srchttp62232161231freeinfoimagesrightsidestuffjpgP',\n",
       " 'Brochure',\n",
       " 'vianbspemailFONTTDTR',\n",
       " 'v006',\n",
       " 'saul',\n",
       " 'SRChttpclickthruonlinecomClickq852G3ogKNokoqVnwlezVayGtOURRR',\n",
       " 'XWAzdlAu7hkPRLbGd3yX67ougTEc6R978n6xYYnhpWuKCOrrvmCAZfW0jS7ACdBxX2qZIiKehr',\n",
       " 'IANAL',\n",
       " 'installdownload',\n",
       " 'namephone',\n",
       " 'WuprdYX31zS542Nra3p2N6zXWOc72fbMv7LAKX1P5pGx5oAl4Afi5uJRk10erY5uFjvMjJeP0rg',\n",
       " 'WillRetryUntil',\n",
       " 'LMh6DALoL58CVaDAMTIIzpRMs8z37807zX7f22dRlVlOQ4TY8Yyn9ZP119Db0RRYt',\n",
       " 'THIS',\n",
       " 'musical',\n",
       " 'squatters',\n",
       " 'partners',\n",
       " 'uncSamMediumgif1Last',\n",
       " 'threat20',\n",
       " 'nIX4AWExHXGJMDJpPrywM0d6J60oCSfsDvfBFAp6EO8oQ8ygIEgCAqQmyxku30JDTaxiA65uIVg',\n",
       " 'gnomies',\n",
       " 'httpwwwgreebliecom',\n",
       " 'hrefhttpclickthruonlinecomClickq77u6h6IIpsCMkQo7Ux31g9NPmdZPuR',\n",
       " 'CiAgICAgICAgs8yr4assXqhRzwvZm9udD48L3ADQogICAgICAgIDxwIGFsaWduPSJsZWZ0Ij48',\n",
       " 'LANG3D07FONTFONT',\n",
       " 'critics',\n",
       " 'genially',\n",
       " 'hrefhttpclickthruonlinecomClickq08IFoQIRjFUlrv0mOg3FerCpGY9iR',\n",
       " 'Yager',\n",
       " 'signaturebased',\n",
       " 'SRChttpwwwprizeinthebagnetimagesRVmovieOceans11c14jpg',\n",
       " 'io0x300',\n",
       " '10deepmincepiejpg',\n",
       " 'size3D1Day',\n",
       " 'border1br',\n",
       " 'meter',\n",
       " 'httpwwwi4informatikrwthaachendejakobsstandardsjournaljournalhomehtml',\n",
       " 'WC8I',\n",
       " 'unsub5644666412williammonsterjokecom',\n",
       " 'abilities',\n",
       " 'T2E82',\n",
       " 'M65B',\n",
       " 'topnotched',\n",
       " 'juzjUfrVktjurI',\n",
       " 'BRthis',\n",
       " 'height264',\n",
       " 'carburetor',\n",
       " 'httpwwwcncbcca',\n",
       " 'mailtojulianbondvoidstarcom',\n",
       " 'Vacuum',\n",
       " '20020806183451X54243100000mooncampusluthse',\n",
       " 'Progress',\n",
       " 'confortable',\n",
       " '214448',\n",
       " 'multidrop',\n",
       " 'HTMLHEADTITLEUntitled',\n",
       " 'Carrierbfontp',\n",
       " 'hrefhttpclickthruonlinecomClickq9fo7XMQ1JdPBuTQ0oYlcGhVIlcUZR',\n",
       " 'razorusersrequestexamplesourceforgenet',\n",
       " '206',\n",
       " 'selfservice',\n",
       " 'franchisevilles',\n",
       " 'Germs',\n",
       " 'AMAZING',\n",
       " 'lcomemailsz3D468x60ord3D',\n",
       " '6310ABR',\n",
       " 'THERE',\n",
       " 'ICAgICAgPGJyPg0KICAgICAgPC9mb250PjxiPjxmb250IGNvbG9yPSIjZmYwMDAwIiBmYWNlPSJB',\n",
       " '³care',\n",
       " 'BusinessFONTTD',\n",
       " 'dividing',\n",
       " 'C80XMecPMtfgRqUAYnOlbajL3QNDfwds8F1HWB4AVLlfBitwb5URpRvgAILicMvGfS6cp',\n",
       " 'UwuPJSgS6ACRBVqzAjI4AAiQlpOsVoJkdiAnDMgJgBm0IUnwLQLx6ykE5YwhYcuQQoEfSohaPrD',\n",
       " 'UTILIZING',\n",
       " '092227',\n",
       " '193615',\n",
       " 'NextPartKclG2AeIezUiae9B4wAA',\n",
       " 'KM',\n",
       " 'AAAAAAAAAAAAAAAAAAAAAAAAAACAKA4lTnCAYAoDiX5OcIBAAAAAAAAAAAAAAAAAQAAAP7',\n",
       " 'comedian',\n",
       " 'Lifebrbrfontfont',\n",
       " 'able20',\n",
       " 'QUALIFY',\n",
       " 'Negatives',\n",
       " '171333',\n",
       " 'Prev',\n",
       " 'howA',\n",
       " '000066Click',\n",
       " 'Cadastrese',\n",
       " '60026000000213597',\n",
       " 'IA0KICAgICAgICAgICAgICBwbGF5YmFjayByZWNvcmRlZCB2aWRlbzxicj4NCiAgICAgICAgICAg',\n",
       " 'youare',\n",
       " 'height393',\n",
       " 'DAV19uS7sBdxkiiZIHd0000ac6chotmailcom',\n",
       " 'titleYoure',\n",
       " 'onlinecomClickq3D23sFcGINM8KMs305CiAv2Y9ZZvQKrR',\n",
       " 'Blattys',\n",
       " 'pings',\n",
       " 'MSNBC',\n",
       " 'size1fontimg',\n",
       " 'setupnbspli',\n",
       " 'overtones',\n",
       " '152554',\n",
       " 'testsFORFREEINREPTOKNOWNMAILINGLISTREFERENCES',\n",
       " 'salignT',\n",
       " 'd93Hh4vB6PDJrLc4ZyX0Tk42TlnaWSjTR33rhlLiT1Fix2UFiK5nNG0rsPxR0kswyy0dLb6Z2',\n",
       " 'PG9wdGlvbiBzZWxlY3RlZD690Lvvtw8L29wdGlvbj4NCiAgICAgICAgICAgIDxvcHRpb24pLq2',\n",
       " '0758',\n",
       " 'dummy',\n",
       " 'ricochet',\n",
       " '8588127C8BF911D68838003065F890CCKnowNowcom',\n",
       " 'Passionate',\n",
       " 'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0A0AAAAAAADSCgAAAAAAAFoJAAAMAAAAgL71JPk5',\n",
       " 'vacationfontstrongbigp',\n",
       " 'San',\n",
       " 'Korean',\n",
       " 'Gases',\n",
       " 'borderbottomcolor',\n",
       " 'CLASSblack',\n",
       " 'href3Dhttpwwwfastbizonlinecomremovemehtml',\n",
       " 'hrefhttpclickthruonlinecomClickq76vJf7InBP3QFd7XP1okYP2r70U6iR',\n",
       " '20020827',\n",
       " 'bDavid',\n",
       " 'classregblksforspannbsptd',\n",
       " 'disarray',\n",
       " 'QkxFPjwvVEQPC9UUj4NCiAgICAgICAgICAgICAgICAgICAgPFRSPjwhLS0gY2hvaWNlX3Byb2R1',\n",
       " 'Alertsbr',\n",
       " '‘Adolf',\n",
       " 'retorted',\n",
       " 'Chargefontbfontfont',\n",
       " '20020808152638A32536frontierlimbonet',\n",
       " 'Knickerstitle',\n",
       " 'color000000Starring',\n",
       " 'href3DhttpclickthruonlinecomClickq3De0cISRQfDH08pTG',\n",
       " 'innerestin',\n",
       " 'href3Dhttpwwwany',\n",
       " 'shooter',\n",
       " 'XgedkyW502BMWHtEEsFhwCs5f31PFVAoEeKxLh7MSDnpXQYEaPwiTxVfKJ99KcwQj6dlfAcAMWW',\n",
       " 'httpclickthruonlinecomClickq68iM8qIsPPH1noIAYywvjsKFdLPRR',\n",
       " 'Yahoobr',\n",
       " 'httpwwwcoxesroostnetpeanutscategoriesradioUserland',\n",
       " 'infringement',\n",
       " 'srchttpakbuycombuyassetsv6emailCNET062402FStruckgif',\n",
       " 'hrefhttpwwwSellSharewarecomProgramInfoaspAfID10519PrID36034Get',\n",
       " 'Texass',\n",
       " 'lingerie',\n",
       " 'LCBpbiB0aGUgcGFzdCA4IG1vbnRocyBieSByZS1lbnRlcmluZyB0aGUgcHJv',\n",
       " 'Irwin',\n",
       " 'face3DArialNo',\n",
       " 'tcclass3D4scrip',\n",
       " 'blacka',\n",
       " 'value1717option',\n",
       " 'resolution',\n",
       " 'READ',\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(get_unique_words(df)))\n",
    "get_unique_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_words_row(df_row):\n",
    "    return [a.strip() for a in re.split(r'[\\s,\\n\\.]+', df_row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_map(words, row):\n",
    "    \"\"\"\n",
    "    Passing in a list of unique cuisines that has been generated previously.\n",
    "    We compare the cuisines in a particular row and return a binary list of 0 for False, 1 for True in the cuisines is\n",
    "    in the row values.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [(a in row)*1 for a in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_words_df(df):\n",
    "    df_full = pd.DataFrame(df)\n",
    "    df_full = df_full[df_full['body'].notna()]\n",
    "    #print(df_full.head())\n",
    "    try:\n",
    "        df_full.reset_index(inplace = True)\n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "        print(\"Index not reset\")\n",
    "    mapping_dict = {}\n",
    "    unique_words = get_unique_words(df_full)\n",
    "    print(len(unique_words))\n",
    "    for i in tqdm(range(df_full.shape[0])):\n",
    "        try:\n",
    "            df_row = prep_words_row(df_full['body'][i])\n",
    "        except:\n",
    "            print(df_full['body'][i])\n",
    "            print(type(df_full['body'][i]))\n",
    "        word_map = get_word_map(unique_words, df_row)\n",
    "        mapping_dict[df_full['index'][i]] = word_map\n",
    "    word_mapping_df = pd.DataFrame.from_dict(mapping_dict, orient = 'index', columns = unique_words)\n",
    "    return word_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/8517 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 3/8517 [00:04<3:11:17,  1.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-89493d79b23d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_mapping_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_words_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_mapping_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-a3dc8adba444>\u001b[0m in \u001b[0;36mparse_words_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mword_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mmapping_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mword_mapping_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-fe0b4d9febf2>\u001b[0m in \u001b[0;36mget_word_map\u001b[1;34m(words, row)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-fe0b4d9febf2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_mapping_df = parse_words_df(df)\n",
    "word_mapping_df.shapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-260a1966fc24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     return [\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     ]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     return [\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     ]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENDING_QUOTES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['words'] = df['body'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_map = str.maketrans(dict.fromkeys(string.punctuation, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df['body'].str.translate(punc_map).str.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\\nReferences: <1029945287.4797.TMDA@deepeddy.vircio.com>\\n<1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\\n<1029943066.26919.TMDA@deepeddy.vircio.com>\\n<1029944441.398.TMDA@deepeddy.vircio.com>\\nMIME-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nMessage-Id: <13258.1030015585@munnari.OZ.AU>\\nX-Loop: exmh-workers@example.com\\nSender: exmh-workers-admin@example.com\\nErrors-To: exmh-workers-admin@example.com\\nX-Beenthere: exmh-workers@example.com\\nX-Mailman-Version: 2.0.1\\nPrecedence: bulk\\nList-Help: <mailto:exmh-workers-request@example.com?subject=help>\\nList-Post: <mailto:exmh-workers@example.com>\\nList-Subscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=subscribe>\\nList-Id: Discussion list for EXMH developers <exmh-workers.example.com>\\nList-Unsubscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\\nList-Archive: <https://listman.example.com/mailman/private/exmh-workers/>\\nDate: Thu, 22 Aug 2002 18:26:25 +0700\\n\\nDate:        Wed, 21 Aug 2002 10:54:46 -0500\\nFrom:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\\nMessage-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\\n\\n\\n| I can\\'t reproduce this error.\\n\\nFor me it is very repeatable... (like every time, without fail).\\n\\nThis is the debug log of the pick happening ...\\n\\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\\n18:19:04 Ftoc_PickMsgs {{1 hit}}\\n18:19:04 Marking 1 hits\\n18:19:04 tkerror: syntax error in expression \"int ...\\n\\nNote, if I run the pick command by hand ...\\n\\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\\n1 hit\\n\\nThat\\'s where the \"1 hit\" comes from (obviously).  The version of nmh I\\'m\\nusing is ...\\n\\ndelta$ pick -version\\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\\n\\nAnd the relevant part of my .mh_profile ...\\n\\ndelta$ mhparam pick\\n-seq sel -list\\n\\n\\nSince the pick command works, the sequence (actually, both of them, the\\none that\\'s explicit on the command line, from the search popup, and the\\none that comes from .mh_profile) do get created.\\n\\nkre\\n\\nps: this is still using the version of the code form a day ago, I haven\\'t\\nbeen able to reach the cvs repository today (local routing issue I think).\\n\\n\\n\\n_______________________________________________\\nExmh-workers mailing list\\nExmh-workers@redhat.com\\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['References',\n",
       " 'JHEPKCEMGPKFFDHHDDKDOECGFCAAbillwstoddardcom\\nContentType',\n",
       " 'multipartrelated\\nboundary080808010909060409040405\\nSender',\n",
       " 'forkadminxentcom\\nErrorsTo',\n",
       " 'forkadminxentcom\\nXBeenthere',\n",
       " 'forkexamplecom\\nXMailmanVersion',\n",
       " '2011\\nPrecedence',\n",
       " 'bulk\\nListHelp',\n",
       " 'mailtoforkrequestxentcomsubjecthelp\\nListPost',\n",
       " 'mailtoforkexamplecom\\nListSubscribe',\n",
       " 'httpxentcommailmanlistinfofork',\n",
       " 'mailtoforkrequestxentcomsubjectsubscribe\\nListId',\n",
       " 'Friends',\n",
       " 'of',\n",
       " 'Rohit',\n",
       " 'Khare',\n",
       " 'forkxentcom\\nListUnsubscribe',\n",
       " 'httpxentcommailmanlistinfofork\\nmailtoforkrequestxentcomsubjectunsubscribe\\nListArchive',\n",
       " 'httpxentcompipermailfork\\nDate',\n",
       " 'Thu',\n",
       " '22',\n",
       " 'Aug',\n",
       " '2002',\n",
       " '182548',\n",
       " '0300\\nXPyzor',\n",
       " 'Reported',\n",
       " '0',\n",
       " 'times\\nXSpamStatus',\n",
       " 'No',\n",
       " 'hits67',\n",
       " 'required70\\ntestsEMAILATTRIBUTIONKNOWNMAILINGLISTREFERENCES\\nSPAMPHRASE0102USERAGENTUSERAGENTMOZILLAUA\\nXACCEPTLANG\\nversion240cvs\\nXSpamLevel\\n\\n\\n080808010909060409040405\\nContentType',\n",
       " 'textplain',\n",
       " 'charsetusascii',\n",
       " 'formatflowed\\nContentTransferEncoding',\n",
       " '7bit\\n\\nBill',\n",
       " 'Stoddard',\n",
       " 'wrote\\n\\nNo',\n",
       " 'one',\n",
       " 'likes',\n",
       " 'commercial',\n",
       " 'spam\\n\\n\\nAnd',\n",
       " 'no',\n",
       " 'one',\n",
       " 'like',\n",
       " 'unsolicited',\n",
       " 'political',\n",
       " 'spam',\n",
       " 'End',\n",
       " 'of',\n",
       " 'story\\n\\nBill\\nhttpxentcommailmanlistinfofork\\n\\n\\nExcept',\n",
       " 'perhaps',\n",
       " 'for',\n",
       " 'the',\n",
       " 'people',\n",
       " 'in',\n",
       " 'charge\\nOwen\\n\\nhttpzdnetcomcom21001105954903html\\n\\n\\nPolitical',\n",
       " 'spam',\n",
       " 'on',\n",
       " 'your',\n",
       " 'cell',\n",
       " 'phone\\nBy',\n",
       " 'Lisa',\n",
       " 'M',\n",
       " 'Bowman',\n",
       " 'mailtolisabowmancnetcom\\nSpecial',\n",
       " 'to',\n",
       " 'ZDNet',\n",
       " 'News\\nAugust',\n",
       " '22',\n",
       " '2002',\n",
       " '1205',\n",
       " 'PM',\n",
       " 'PT\\nURL',\n",
       " 'httpzdnetcomcom21001105954909html\\n2020202020202020202020202020202020202020httpzdnetcomcom21001105954909html0A20202020202020202020202020202020\\n\\n\\nIn',\n",
       " 'a',\n",
       " 'decision',\n",
       " 'that',\n",
       " 'treats',\n",
       " 'text',\n",
       " 'messaging',\n",
       " 'on',\n",
       " 'mobile',\n",
       " 'phones',\n",
       " 'essentially\\nthe',\n",
       " 'same',\n",
       " 'as',\n",
       " 'bumper',\n",
       " 'stickers',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Election',\n",
       " 'Commission',\n",
       " 'has\\ndeclared',\n",
       " 'that',\n",
       " 'senders',\n",
       " 'of',\n",
       " 'textbased',\n",
       " 'political',\n",
       " 'ads',\n",
       " 'dont',\n",
       " 'have',\n",
       " 'to',\n",
       " 'disclose\\nwho',\n",
       " 'funded',\n",
       " 'them\\n\\nIn',\n",
       " 'an',\n",
       " 'advisory',\n",
       " 'opinion',\n",
       " 'issued',\n",
       " 'Thursday',\n",
       " 'the',\n",
       " 'FEC',\n",
       " 'also',\n",
       " 'suggested',\n",
       " 'such\\nmessages',\n",
       " 'include',\n",
       " 'either',\n",
       " 'a',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'or',\n",
       " 'Web',\n",
       " 'site',\n",
       " 'link',\n",
       " 'so',\n",
       " 'people',\n",
       " 'could\\neasily',\n",
       " 'learn',\n",
       " 'who',\n",
       " 'paid',\n",
       " 'for',\n",
       " 'the',\n",
       " 'message',\n",
       " 'However',\n",
       " 'the',\n",
       " 'additional\\ninformation',\n",
       " 'wont',\n",
       " 'be',\n",
       " 'required\\n\\nThe',\n",
       " 'opinion',\n",
       " 'could',\n",
       " 'encourage',\n",
       " 'the',\n",
       " 'adoption',\n",
       " 'of',\n",
       " 'textbased',\n",
       " 'political',\n",
       " 'ads',\n",
       " 'as\\ncampaign',\n",
       " 'experts',\n",
       " 'look',\n",
       " 'for',\n",
       " 'new',\n",
       " 'technological',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'sway',\n",
       " 'voters',\n",
       " 'At',\n",
       " 'the\\nsame',\n",
       " 'time',\n",
       " 'opponents',\n",
       " 'of',\n",
       " 'the',\n",
       " 'plan',\n",
       " 'fear',\n",
       " 'it',\n",
       " 'could',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'anonymous\\npolitical',\n",
       " 'spam\\n\\nTarget',\n",
       " 'Wireless',\n",
       " 'a',\n",
       " 'small',\n",
       " 'New',\n",
       " 'Jerseybased',\n",
       " 'wireless',\n",
       " 'media',\n",
       " 'company',\n",
       " 'had\\nasked',\n",
       " 'the',\n",
       " 'FEC',\n",
       " 'for',\n",
       " 'an',\n",
       " 'opinion',\n",
       " 'on',\n",
       " 'the',\n",
       " 'matter',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'requiring\\nfinancial',\n",
       " 'disclosures',\n",
       " 'on',\n",
       " 'short',\n",
       " 'messaging',\n",
       " 'service',\n",
       " 'SMS',\n",
       " 'mailings',\n",
       " 'would\\nuse',\n",
       " 'up',\n",
       " 'too',\n",
       " 'much',\n",
       " 'of',\n",
       " 'the',\n",
       " '160',\n",
       " 'charactermaximum\\n\\nPolitical',\n",
       " 'messages',\n",
       " 'on',\n",
       " 'bumper',\n",
       " 'stickers',\n",
       " 'and',\n",
       " 'buttons',\n",
       " 'are',\n",
       " 'also',\n",
       " 'exempt',\n",
       " 'from\\nthe',\n",
       " 'financial',\n",
       " 'disclosure',\n",
       " 'requirement',\n",
       " 'Target',\n",
       " 'Wireless',\n",
       " 'petition',\n",
       " 'was\\nsupported',\n",
       " 'by',\n",
       " 'the',\n",
       " 'National',\n",
       " 'Republican',\n",
       " 'Senatorial',\n",
       " 'Committee',\n",
       " 'the',\n",
       " 'Cellular\\nTelecommunications',\n",
       " 'and',\n",
       " 'Internet',\n",
       " 'Association',\n",
       " 'and',\n",
       " 'some',\n",
       " 'advertising',\n",
       " 'trade\\ngroups\\n\\nFEC',\n",
       " 'spokesman',\n",
       " 'Bob',\n",
       " 'Biersack',\n",
       " 'said',\n",
       " 'the',\n",
       " 'opinion',\n",
       " 'was',\n",
       " 'in',\n",
       " 'keeping',\n",
       " 'with',\n",
       " 'the\\ncommissions',\n",
       " 'policy',\n",
       " 'not',\n",
       " 'to',\n",
       " 'meddle',\n",
       " 'with',\n",
       " 'new',\n",
       " 'technology',\n",
       " 'that',\n",
       " 'has',\n",
       " 'the\\npotential',\n",
       " 'to',\n",
       " 'reach',\n",
       " 'more',\n",
       " 'voters\\n\\nWe',\n",
       " 'have',\n",
       " 'tried',\n",
       " 'very',\n",
       " 'hard',\n",
       " 'not',\n",
       " 'to',\n",
       " 'get',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wayparticularly',\n",
       " 'before\\neveryone',\n",
       " 'understands',\n",
       " 'how',\n",
       " 'the',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'work',\n",
       " 'he',\n",
       " 'said\\n\\nOpponents',\n",
       " 'of',\n",
       " 'the',\n",
       " 'plan',\n",
       " 'have',\n",
       " 'worried',\n",
       " 'the',\n",
       " 'exemption',\n",
       " 'might',\n",
       " 'encourage',\n",
       " 'spam',\n",
       " 'or\\nallow',\n",
       " 'senders',\n",
       " 'to',\n",
       " 'blast',\n",
       " 'people',\n",
       " 'with',\n",
       " 'mass',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'negative',\n",
       " 'political\\nmessages',\n",
       " 'while',\n",
       " 'remaining',\n",
       " 'anonymous\\n\\nBiersack',\n",
       " 'said',\n",
       " 'the',\n",
       " 'FEC',\n",
       " 'can',\n",
       " 'revisit',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'if',\n",
       " 'those',\n",
       " 'problems',\n",
       " 'surface\\n\\nTarget',\n",
       " 'Wireless',\n",
       " 'President',\n",
       " 'Craig',\n",
       " 'Krueger',\n",
       " 'characterized',\n",
       " 'the',\n",
       " 'opinion',\n",
       " 'as\\ngood',\n",
       " 'for',\n",
       " 'America\\n\\nIt',\n",
       " 'will',\n",
       " 'allow',\n",
       " 'people',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'more',\n",
       " 'communication',\n",
       " 'from',\n",
       " 'those',\n",
       " 'running\\nfor',\n",
       " 'office',\n",
       " 'he',\n",
       " 'said',\n",
       " 'We',\n",
       " 'have',\n",
       " 'free',\n",
       " 'speech',\n",
       " 'on',\n",
       " 'our',\n",
       " 'side\\n\\n\\n\\n\\n080808010909060409040405\\n\\nhttpxentcommailmanlistinfofork\\n']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words'][100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
