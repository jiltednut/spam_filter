{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Liam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Liam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import bz2\n",
    "import tarfile\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Language processing\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# URL libs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to specify where to get the email data (lib_url) and where to save it (main_dir, sub_dir)\n",
    "# These will be referenced in the data curation phase of execution.\n",
    "lib_url = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "main_dir = \"data\"\n",
    "sub_dir = \"extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_structure(main_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Function to create the directory structure on disk in the case that it doesn't already exist\n",
    "    The directory will be created in the same directory as the source file and will use the structure main_dir/sub_dir\n",
    "    Input:\n",
    "        main_dir: the top level of the directory structure\n",
    "        sub_dir: sublevel in the directory structure\n",
    "    Returns:\n",
    "        No return.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(\".\\\\\" + main_dir)\n",
    "    except:\n",
    "        print(\"Directory already exists.\")\n",
    "        try:\n",
    "            os.mkdir(\".\\\\\"+ main_dir +\"\\\\\"+ sub_dir +\"\\\\\")\n",
    "        except:\n",
    "            print(\"Directory already exists.\")\n",
    "    print(\"Directory Structure Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_email_records(url):\n",
    "    \"\"\"\n",
    "    Function to download the page source from online directory and create a list of filenames with .tar.bz2 extensions\n",
    "    Input:\n",
    "        url: the lib_url defined in the source\n",
    "    Returns:\n",
    "        downloadable: a list of urls made of the lib_url web address and the filenames extracted from the hyperlines in the page source.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(lib_url).text)\n",
    "    urls = soup.find_all('a')\n",
    "    filenames = [url['href'] for url in urls if \"bz2\" in str(url)]\n",
    "    downloadable = [lib_url + filename for filename in filenames]\n",
    "    print(\"Email archive urls extracted\")\n",
    "    return downloadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_email_records(file_urls):\n",
    "    \"\"\"\n",
    "    Function to download the email archives and write them to disk in the directory hierarchy\n",
    "    Input:\n",
    "        file_urls: a list of urls pointing to the email archives\n",
    "    Returns:\n",
    "        No return.\n",
    "    \"\"\"\n",
    "    for i, url in enumerate(file_urls):\n",
    "        dl = requests.get(url, allow_redirects = True)\n",
    "        open(\".//\" + main_dir + \"//\"+file_urls[i].split(\"/\")[-1], 'wb').write(dl.content)\n",
    "    print(\"Email archives downloaded from url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_records(main_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Function to extract the email records from the downloaded email archives.\n",
    "    Loops through all files in each level of the directory hierarchy and extracts the data from all tar.bz2 archives to disk.\n",
    "    Input:\n",
    "        main_dir: the top level of the directory structure\n",
    "        sub_dir: sublevel in the directory structure\n",
    "    Returns:\n",
    "        No return.\n",
    "    \"\"\"\n",
    "    for filepath in glob.glob(\".\\\\\" + main_dir + \"\\\\*.tar.bz2\"):\n",
    "        #zipfile = bz2.BZ2File(filepath)\n",
    "        #data = zipfile.read()\n",
    "        #newfile = filepath[:-4]\n",
    "        #open(newfile, \"wb\").write(data)\n",
    "        tar = tarfile.open(filepath, \"r:bz2\")\n",
    "        tar.extractall(os.path.join(main_dir+ \"\\\\\"+ sub_dir, filepath[7:-8]))\n",
    "        tar.close()\n",
    "    print(\"Email records extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_and_create_email_records(url, main_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Wrapper function to download and create the email records from the archive.\n",
    "    \"\"\"\n",
    "    urls = download_email_records(url)\n",
    "    create_directory_structure(main_dir = main_dir, sub_dir = sub_dir)\n",
    "    save_email_records(file_urls = urls)\n",
    "    extract_email_records(main_dir = main_dir, sub_dir = sub_dir)\n",
    "    print(\"Email records downloaded & extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_directory_details(target_dir, sub_dir):\n",
    "    \"\"\"\n",
    "    Function to traverse a directory and record the target type of each folder by checking if the folder\n",
    "    contains either \"HAM\" or \"SPAM\" in the name.\n",
    "    Input:\n",
    "        target_dir: the target directory\n",
    "        sub_dir: the sub directory\n",
    "    Returns:\n",
    "        email_type_names: a list containing the folder path, in the sub_dir, and the target type based on the folder name.\n",
    "    \"\"\"\n",
    "    sub_directories = glob.glob(target_dir + \"\\\\\"+ sub_dir +\"\\\\*\\\\*\")\n",
    "#     print(target_dir)\n",
    "#     print(os.path.join(target_dir, \"\\\\extracted\\\\*\\\\*\"))\n",
    "#     print(sub_directories)\n",
    "    names = [(x.split(\"\\\\\")[-1], \"HAM\" if x.find(\"ham\") >=0 else \"SPAM\") for x in sub_directories]\n",
    "    email_type_names = list(zip(names, sub_directories))\n",
    "    print(\"Target directories extracted\")\n",
    "    return email_type_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(email, line_names, target):\n",
    "    \"\"\"\n",
    "    Function to take in the filename of an email document.\n",
    "    Extract any information relating to the predefined tags\n",
    "    Store any information after the subject line as body - to be further processed later\n",
    "    Input:\n",
    "        email: the email text file, extracted from the email archive\n",
    "        line_names: a predefined list of line start strings that will correspond to column headers later\n",
    "        target: the target type extracted from the home folder of the email file.\n",
    "    Returns:\n",
    "        value_dict: a dictionary with the extracted body text, target type and key-value pairs for the line_names values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(email) as file:\n",
    "            body_start = False # Changed to True after reading the subject tag.\n",
    "            body = []\n",
    "            value_dict = {}\n",
    "            value_dict['target'] = target\n",
    "\n",
    "            for line in file.readlines():\n",
    "                line_start = line.split(\":\")[0]+\":\"\n",
    "                if body_start:\n",
    "                    body.append(line.strip())\n",
    "                if line_start in line_names:\n",
    "                    line_contents = re.findall(r\":\\s(.*)\", line)[0]\n",
    "                    value_dict[line_start] = line_contents\n",
    "                if line_start == \"Subject:\":\n",
    "                    body_start = True\n",
    "            value_dict['body'] = \"\\n\".join(body)\n",
    "            return value_dict\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: Error: Can't read file {email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_target_mappings(main_dir):\n",
    "    \"\"\"\n",
    "    Function to map the target type to the folder name.\n",
    "    Used to map the target to the individual email text files later.\n",
    "    Input:\n",
    "        main_dir: The directory that needs to be mapped\n",
    "    Returns:\n",
    "        target_mapping: list of tuples containing the folder path & the target type (\"HAM\" or \"SPAM\").    \n",
    "    \"\"\"\n",
    "    email_type_names = get_target_directory_details(\".\\\\\" + main_dir, sub_dir)\n",
    "    directories = [x[1] for x in email_type_names]\n",
    "    targets = [x[0][1] for x in email_type_names]\n",
    "    target_mapping = list(zip(directories, targets))\n",
    "    print(\"Target mappings extracted\")\n",
    "    return target_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_file_listing(dir_path):\n",
    "    \"\"\"\n",
    "    Function to create a list of all the file paths in a directory\n",
    "    Input:\n",
    "        dir_path: the file path of a directory\n",
    "    Returns:\n",
    "        a list of all files in the directory.\n",
    "    \"\"\"\n",
    "    print(dir_path + \"\\\\\")\n",
    "    return glob.glob(dir_path + \"\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_data_to_dictionary(main_dir):\n",
    "    \"\"\"\n",
    "    Function to extract the details from the email text files and store in a dictionary\n",
    "    Inputs:\n",
    "        main_dir: the directory containing the email text files\n",
    "    Returns:\n",
    "        email_contents: dictionary containing the extracted dictionaries from the function parse_email().\n",
    "    \"\"\"\n",
    "    line_names = [\"To:\", \"From:\", \"MIME-Version:\", \"Content-Type:\",\n",
    "                 \"Content-Transfer-Encoding:\", \"X-Mailer:\", \"Subject:\",\n",
    "                 \"Precedence:\"]\n",
    "\n",
    "    target_mapping = get_email_target_mappings(main_dir = main_dir)\n",
    "    email_contents = {}\n",
    "    for target in target_mapping:\n",
    "        for file in get_directory_file_listing(target[0]):\n",
    "            email_contents[file.split(\"\\\\\")[-1]] = parse_email(file, line_names, target[1])\n",
    "    print(\"Emails extracted to dictionary\")\n",
    "    return email_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_dataframe(email_dict):\n",
    "    \"\"\"\n",
    "    Function to convert a dictionary to a dataframe and tranpose the resulting dataframe.\n",
    "    Input:\n",
    "        email_dict: a dictionary containing dictionaries with extracted email information\n",
    "    Returns:\n",
    "        df: dataframe generated from the dictionary, transposed to keep keys as the columns and not as the rows.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(email_dict).transpose().reset_index()\n",
    "    print(\"DataFrame generated\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_email_dataframe():\n",
    "    \"\"\"\n",
    "    Wrapper function to return a dataframe from the extracted email archives\n",
    "    \"\"\"\n",
    "    email_dict = extract_email_data_to_dictionary(main_dir = main_dir)\n",
    "    print(\"Base dataframe ready for cleansing\")\n",
    "    return convert_dict_to_dataframe(email_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target directories extracted\n",
      "Target mappings extracted\n",
      ".\\data\\extracted\\20021010_easy_ham\\easy_ham\\\n",
      ".\\data\\extracted\\20021010_hard_ham\\hard_ham\\\n",
      ".\\data\\extracted\\20021010_spam\\spam\\\n",
      "'charmap' codec can't decode byte 0x81 in position 3082: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0123.68e87f8b736959b1ab5c4b5f2ce7484a\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0255.42a6feb4435a0a68929075c0926f085d\n",
      "'charmap' codec can't decode byte 0x81 in position 2588: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0273.51c482172b47ce926021aa7cc2552549\n",
      "'charmap' codec can't decode byte 0x81 in position 2503: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0330.a4df526233e524104c3b3554dd8ab5a8\n",
      "'charmap' codec can't decode byte 0x81 in position 2682: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0334.3e4946e69031f3860ac6de3d3f27aadd\n",
      "'charmap' codec can't decode byte 0x81 in position 2728: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20021010_spam\\spam\\0335.9822e1787fca0741a8501bdef7e8bc79\n",
      ".\\data\\extracted\\20030228_easy_ham\\easy_ham\\\n",
      ".\\data\\extracted\\20030228_easy_ham_2\\easy_ham_2\\\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_easy_ham_2\\easy_ham_2\\00664.28f4cb9fad800d0c7175d3a67e6c6458\n",
      ".\\data\\extracted\\20030228_hard_ham\\hard_ham\\\n",
      ".\\data\\extracted\\20030228_spam\\spam\\\n",
      "'charmap' codec can't decode byte 0x81 in position 3124: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00116.29e39a0064e2714681726ac28ff3fdef\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00245.f129d5e7df2eebd03948bb4f33fa7107\n",
      "'charmap' codec can't decode byte 0x81 in position 2568: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00263.13fc73e09ae15e0023bdb13d0a010f2d\n",
      "'charmap' codec can't decode byte 0x81 in position 2483: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00320.20dcbb5b047b8e2f212ee78267ee27ad\n",
      "'charmap' codec can't decode byte 0x81 in position 2662: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00323.9e36bf05304c99f2133a4c03c49533a9\n",
      "'charmap' codec can't decode byte 0x81 in position 2708: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00324.6f320a8c6b5f8e4bc47d475b3d4e86ef\n",
      "'charmap' codec can't decode byte 0x8f in position 1674: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam\\spam\\00500.85b72f09f6778a085dc8b6821965a76f\n",
      ".\\data\\extracted\\20030228_spam_2\\spam_2\\\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\00721.09d243c9c4da88c5f517003d26196aaa\n",
      "'charmap' codec can't decode byte 0x8d in position 3062: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01065.9ecef01b01ca912fa35453196b4dae4c\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01083.a6b3c50be5abf782b585995d2c11176b\n",
      "'charmap' codec can't decode byte 0x90 in position 2832: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01227.04a4f94c7a73b29cb56bf38c7d526116\n",
      "'charmap' codec can't decode byte 0x9d in position 4099: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20030228_spam_2\\spam_2\\01376.73e738e4cd8121ce3dfb42d190b193c9\n",
      ".\\data\\extracted\\20050311_spam_2\\spam_2\\\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\00721.09d243c9c4da88c5f517003d26196aaa\n",
      "'charmap' codec can't decode byte 0x8d in position 3062: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01065.9ecef01b01ca912fa35453196b4dae4c\n",
      "list index out of range: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01083.a6b3c50be5abf782b585995d2c11176b\n",
      "'charmap' codec can't decode byte 0x90 in position 2832: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01227.04a4f94c7a73b29cb56bf38c7d526116\n",
      "'charmap' codec can't decode byte 0x9d in position 4099: character maps to <undefined>: Error: Can't read file .\\data\\extracted\\20050311_spam_2\\spam_2\\01376.73e738e4cd8121ce3dfb42d190b193c9\n",
      "Emails extracted to dictionary\n",
      "Base dataframe ready for cleansing\n",
      "DataFrame generated\n"
     ]
    }
   ],
   "source": [
    "dl_and_create_email_records(lib_url, main_dir, sub_dir)\n",
    "base_email_df = generate_base_email_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>From:</th>\n",
       "      <th>To:</th>\n",
       "      <th>Subject:</th>\n",
       "      <th>MIME-Version:</th>\n",
       "      <th>Content-Type:</th>\n",
       "      <th>Precedence:</th>\n",
       "      <th>body</th>\n",
       "      <th>X-Mailer:</th>\n",
       "      <th>Content-Transfer-Encoding:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.ea7e79d3153e7469e7a9c3e0af6a357e</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Robert Elz &lt;kre@munnari.OZ.AU&gt;</td>\n",
       "      <td>Chris Garrigues &lt;cwg-dated-1030377287.06fa6d@D...</td>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>bulk</td>\n",
       "      <td>In-Reply-To: &lt;1029945287.4797.TMDA@deepeddy.vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.b3120c4bcbf3101e661161ee7efcb8bf</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Steve Burt &lt;Steve_Burt@cursor-system.com&gt;</td>\n",
       "      <td>\"'zzzzteana@yahoogroups.com'\" &lt;zzzzteana@yahoo...</td>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=US-ASCII</td>\n",
       "      <td>bulk</td>\n",
       "      <td>Reply-To: zzzzteana@yahoogroups.com\\nContent-T...</td>\n",
       "      <td>Internet Mail Service (5.5.2653.19)</td>\n",
       "      <td>7bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.acfc5ad94bbd27118a0d8685d18c89dd</td>\n",
       "      <td>HAM</td>\n",
       "      <td>\"Tim Chapman\" &lt;timc@2ubh.com&gt;</td>\n",
       "      <td>zzzzteana &lt;zzzzteana@yahoogroups.com&gt;</td>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=US-ASCII</td>\n",
       "      <td>bulk</td>\n",
       "      <td>Reply-To: zzzzteana@yahoogroups.com\\nContent-T...</td>\n",
       "      <td>Microsoft Outlook Express Macintosh Edition - ...</td>\n",
       "      <td>7bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.e8d5727378ddde5c3be181df593f1712</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Monty Solomon &lt;monty@roscom.com&gt;</td>\n",
       "      <td>undisclosed-recipient: ;</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=\"us-ascii\"</td>\n",
       "      <td>bulk</td>\n",
       "      <td>Sender: irregulars-admin@tb.tf\\nErrors-To: irr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.8c3b9e9c0f3f183ddaf7592a11b99957</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Tony Nugent &lt;tony@linuxworks.com.au&gt;</td>\n",
       "      <td>Exmh Users Mailing List &lt;exmh-users@example.com&gt;</td>\n",
       "      <td>Re: Insert signature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bulk</td>\n",
       "      <td>X-Loop: exmh-users@example.com\\nSender: exmh-u...</td>\n",
       "      <td>nmh-1.0.4 exmh-2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>01396.e80a10644810bc2ae3c1b58c5fd38dfa</td>\n",
       "      <td>SPAM</td>\n",
       "      <td>Professional_Career_Development_Institute@Frug...</td>\n",
       "      <td>yyyy@netnoteinc.com</td>\n",
       "      <td>Busy? Home Study Makes Sense!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Id-Frugaljoe: yyyy####netnoteinc.com\\nDate: Tu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>01397.f75f0dd0dd923faefa3e9cc5ecb8c906</td>\n",
       "      <td>SPAM</td>\n",
       "      <td>\"IQ - TBA\" &lt;tba@insiq.us&gt;</td>\n",
       "      <td>&lt;yyyy@spamassassin.taint.org&gt;</td>\n",
       "      <td>Preferred Non-Smoker Rates for Smokers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/html;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To: &lt;yyyy@spamassassin.taint.org&gt;\\nDate: Tue, ...</td>\n",
       "      <td>Microsoft CDO for Windows 2000</td>\n",
       "      <td>quoted-printable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>01398.8ca7045aae4184d56e8509dc5ad6d979</td>\n",
       "      <td>SPAM</td>\n",
       "      <td>Mike &lt;raye@yahoo.lv&gt;</td>\n",
       "      <td>Mailing.List@user2.pro-ns.net</td>\n",
       "      <td>How to get 10,000 FREE hits per day to any web...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sender: Mike &lt;raye@yahoo.lv&gt;\\nMime-Version: 1....</td>\n",
       "      <td>Microsoft Outlook Build 10.0.2616</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9348</th>\n",
       "      <td>01399.2319643317e2c5193d574e40a71809c2</td>\n",
       "      <td>SPAM</td>\n",
       "      <td>\"Mr. Clean\" &lt;cweqx@dialix.oz.au&gt;</td>\n",
       "      <td>&lt;Undisclosed.Recipients@webnote.net&gt;</td>\n",
       "      <td>Cannabis Difference</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date: Wed, 05 Aug 2020 04:01:50 -1900\\nMIME-Ve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9349</th>\n",
       "      <td>01400.b444b69845db2fa0a4693ca04e6ac5c5</td>\n",
       "      <td>SPAM</td>\n",
       "      <td>\"wilsonkamela400@netscape.net\" &lt;wilsonkamela50...</td>\n",
       "      <td>ilug@linux.ie</td>\n",
       "      <td>[ILUG] WILSON  KAMELA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain;charset=\"iso-8859-1\"</td>\n",
       "      <td>bulk</td>\n",
       "      <td>Sender: ilug-admin@linux.ie\\nErrors-To: ilug-a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7bit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9350 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       index target  \\\n",
       "0      0001.ea7e79d3153e7469e7a9c3e0af6a357e    HAM   \n",
       "1      0002.b3120c4bcbf3101e661161ee7efcb8bf    HAM   \n",
       "2      0003.acfc5ad94bbd27118a0d8685d18c89dd    HAM   \n",
       "3      0004.e8d5727378ddde5c3be181df593f1712    HAM   \n",
       "4      0005.8c3b9e9c0f3f183ddaf7592a11b99957    HAM   \n",
       "...                                      ...    ...   \n",
       "9345  01396.e80a10644810bc2ae3c1b58c5fd38dfa   SPAM   \n",
       "9346  01397.f75f0dd0dd923faefa3e9cc5ecb8c906   SPAM   \n",
       "9347  01398.8ca7045aae4184d56e8509dc5ad6d979   SPAM   \n",
       "9348  01399.2319643317e2c5193d574e40a71809c2   SPAM   \n",
       "9349  01400.b444b69845db2fa0a4693ca04e6ac5c5   SPAM   \n",
       "\n",
       "                                                  From:  \\\n",
       "0                        Robert Elz <kre@munnari.OZ.AU>   \n",
       "1             Steve Burt <Steve_Burt@cursor-system.com>   \n",
       "2                         \"Tim Chapman\" <timc@2ubh.com>   \n",
       "3                      Monty Solomon <monty@roscom.com>   \n",
       "4                  Tony Nugent <tony@linuxworks.com.au>   \n",
       "...                                                 ...   \n",
       "9345  Professional_Career_Development_Institute@Frug...   \n",
       "9346                          \"IQ - TBA\" <tba@insiq.us>   \n",
       "9347                               Mike <raye@yahoo.lv>   \n",
       "9348                   \"Mr. Clean\" <cweqx@dialix.oz.au>   \n",
       "9349  \"wilsonkamela400@netscape.net\" <wilsonkamela50...   \n",
       "\n",
       "                                                    To:  \\\n",
       "0     Chris Garrigues <cwg-dated-1030377287.06fa6d@D...   \n",
       "1     \"'zzzzteana@yahoogroups.com'\" <zzzzteana@yahoo...   \n",
       "2                 zzzzteana <zzzzteana@yahoogroups.com>   \n",
       "3                              undisclosed-recipient: ;   \n",
       "4      Exmh Users Mailing List <exmh-users@example.com>   \n",
       "...                                                 ...   \n",
       "9345                                yyyy@netnoteinc.com   \n",
       "9346                      <yyyy@spamassassin.taint.org>   \n",
       "9347                      Mailing.List@user2.pro-ns.net   \n",
       "9348               <Undisclosed.Recipients@webnote.net>   \n",
       "9349                                      ilug@linux.ie   \n",
       "\n",
       "                                               Subject: MIME-Version:  \\\n",
       "0                              Re: New Sequences Window           1.0   \n",
       "1                             [zzzzteana] RE: Alexander           1.0   \n",
       "2                             [zzzzteana] Moscow bomber           1.0   \n",
       "3                 [IRR] Klez: The Virus That  Won't Die           1.0   \n",
       "4                                  Re: Insert signature           NaN   \n",
       "...                                                 ...           ...   \n",
       "9345                      Busy? Home Study Makes Sense!           NaN   \n",
       "9346             Preferred Non-Smoker Rates for Smokers           1.0   \n",
       "9347  How to get 10,000 FREE hits per day to any web...           NaN   \n",
       "9348                                Cannabis Difference           1.0   \n",
       "9349                              [ILUG] WILSON  KAMELA           1.0   \n",
       "\n",
       "                         Content-Type: Precedence:  \\\n",
       "0         text/plain; charset=us-ascii        bulk   \n",
       "1         text/plain; charset=US-ASCII        bulk   \n",
       "2         text/plain; charset=US-ASCII        bulk   \n",
       "3       text/plain; charset=\"us-ascii\"        bulk   \n",
       "4                                  NaN        bulk   \n",
       "...                                ...         ...   \n",
       "9345                         text/html         NaN   \n",
       "9346                        text/html;         NaN   \n",
       "9347  text/plain; charset=\"iso-8859-1\"         NaN   \n",
       "9348                       text/plain;         NaN   \n",
       "9349   text/plain;charset=\"iso-8859-1\"        bulk   \n",
       "\n",
       "                                                   body  \\\n",
       "0     In-Reply-To: <1029945287.4797.TMDA@deepeddy.vi...   \n",
       "1     Reply-To: zzzzteana@yahoogroups.com\\nContent-T...   \n",
       "2     Reply-To: zzzzteana@yahoogroups.com\\nContent-T...   \n",
       "3     Sender: irregulars-admin@tb.tf\\nErrors-To: irr...   \n",
       "4     X-Loop: exmh-users@example.com\\nSender: exmh-u...   \n",
       "...                                                 ...   \n",
       "9345  Id-Frugaljoe: yyyy####netnoteinc.com\\nDate: Tu...   \n",
       "9346  To: <yyyy@spamassassin.taint.org>\\nDate: Tue, ...   \n",
       "9347  Sender: Mike <raye@yahoo.lv>\\nMime-Version: 1....   \n",
       "9348  Date: Wed, 05 Aug 2020 04:01:50 -1900\\nMIME-Ve...   \n",
       "9349  Sender: ilug-admin@linux.ie\\nErrors-To: ilug-a...   \n",
       "\n",
       "                                              X-Mailer:  \\\n",
       "0                                                   NaN   \n",
       "1                   Internet Mail Service (5.5.2653.19)   \n",
       "2     Microsoft Outlook Express Macintosh Edition - ...   \n",
       "3                                                   NaN   \n",
       "4                                    nmh-1.0.4 exmh-2.4   \n",
       "...                                                 ...   \n",
       "9345                                                NaN   \n",
       "9346                     Microsoft CDO for Windows 2000   \n",
       "9347                  Microsoft Outlook Build 10.0.2616   \n",
       "9348                                                NaN   \n",
       "9349                                                NaN   \n",
       "\n",
       "     Content-Transfer-Encoding:  \n",
       "0                           NaN  \n",
       "1                          7bit  \n",
       "2                          7bit  \n",
       "3                           NaN  \n",
       "4                           NaN  \n",
       "...                         ...  \n",
       "9345                        NaN  \n",
       "9346           quoted-printable  \n",
       "9347                        NaN  \n",
       "9348                       7bit  \n",
       "9349                       7bit  \n",
       "\n",
       "[9350 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_email_df = deepcopy(base_email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9350 entries, 0 to 9349\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   index                       9350 non-null   object\n",
      " 1   target                      9331 non-null   object\n",
      " 2   From:                       9329 non-null   object\n",
      " 3   To:                         9006 non-null   object\n",
      " 4   Subject:                    9322 non-null   object\n",
      " 5   MIME-Version:               6208 non-null   object\n",
      " 6   Content-Type:               8052 non-null   object\n",
      " 7   Precedence:                 5304 non-null   object\n",
      " 8   body                        9331 non-null   object\n",
      " 9   X-Mailer:                   3650 non-null   object\n",
      " 10  Content-Transfer-Encoding:  4604 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 803.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cleansed_email_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_remove_colon_from_column_name(df):\n",
    "    \"\"\"\n",
    "    Function to remove the colon from the column headers and force the text to lowercase\n",
    "    Input:\n",
    "        df: the target dataframe\n",
    "    Returns:\n",
    "        df: df with renamed columns\n",
    "    \"\"\"\n",
    "    df.columns = [x.replace(\":\", \"\").lower() for x in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_components_to_features(df, user_types):\n",
    "    \"\"\"\n",
    "    Function to extract components of the to & from columns to new features\n",
    "        fullname: the fullname of the sender that prefixs the email address\n",
    "        email: the full email address contained in '<email_address>'\n",
    "        username: the username from the email address (everything before @)\n",
    "        domain: the domain of the email address (everything after @)\n",
    "    Inputs:\n",
    "        df: the target dataframe\n",
    "        user_types: list of types of user that will be processed i.e. ['to'], ['from'], ['to', 'from']\n",
    "    Returns:\n",
    "        df: df with additional features added.\n",
    "    \"\"\"\n",
    "    for user_type in user_types:\n",
    "        # Split the FROM column into full name, username and domain\n",
    "        # df[str(user_type + '_fullname')] = df[str(user_type)].str.split(\"<\", n = 1).str[0].str.replace('\"', \"\")\n",
    "        df[str(user_type + '_fullname')] = df[str(user_type)].str.extract(r'[$\\s\\\"]?([\\w\\d\\s]*)[\\s\\\"]')[0]\n",
    "\n",
    "        # Extract the from email\n",
    "        # df[str(user_type + '_email')] = df[str(user_type)].str.split(\"<\").str[1].str.replace('>', \"\")\n",
    "        # df[str(user_type + '_email')] = df[str(user_type)].str.extract(r'[\\s<]?([\\w\\d\\+]*@.*\\.[\\w\\d]*)')[0]\n",
    "        df[str(user_type + '_email')] = df[str(user_type)].str.extract(r'([\\w\\d\\+]+@[\\w\\d]+\\.[\\w\\d]+)')[0]\n",
    "        df[str(user_type + '_email_count')] = df[str(user_type)].str.count(r'([\\w\\d\\+]+@[\\w\\d]+\\.[\\w\\d]+)')\n",
    "        \n",
    "        # Extract the from username\n",
    "        df[str(user_type + '_username')] = df[str(user_type + '_email')].str.extract(r'(.*)[@]')\n",
    "\n",
    "        # Extract the from domain\n",
    "        df[str(user_type + '_domain')] = df[str(user_type + '_email')].str.extract(r'[@](.*)')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_invalid_to_from_subject_target_records(df):\n",
    "    \"\"\"\n",
    "    Function to exclude records with invalid target, to, from & subject.\n",
    "    Input:\n",
    "        df: email contents dataframe\n",
    "    Returns:\n",
    "        df: email contents dataframe without invaid target, to, from & subject rows.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df[df['target'].notna()]\n",
    "    df = df[df['to'].notna()]\n",
    "    df = df[df['from'].notna()]\n",
    "    df = df[df['subject'].notna()]\n",
    "    df = df[df['to_email'].notna()]\n",
    "    df = df[df['from_email'].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_type_info_from_content_type_records(df):\n",
    "    \"\"\"\n",
    "    Function to extract format, type, encoding & character set information from the content-type string\n",
    "    Input:\n",
    "        df: email contents dataframe\n",
    "    Returns:\n",
    "        df: email contents dataframe with additional columns for content-type data\n",
    "    \n",
    "    \"\"\"\n",
    "    df['content-type-format'] = df['content-type'].str.lower().str.extract(r'^(\\w+)/')\n",
    "    df['content-type-type'] = df['content-type'].str.lower().str.extract(r'^\\w+/(\\w+)[;\\s]?')\n",
    "    df['content-type-charset'] = df['content-type'].str.lower().str.extract(r'charset[\\s]?=[\\\"]?([\\w\\d-]+)[\\\"\\s]?')\n",
    "    df['content-type-encoding'] = df['content-type'].str.lower().str.extract(r'encoding[\\s]?=[\\\"]?([\\w\\d-]+)[\\\"\\s]?')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try functions\n",
    "cleansed_email_df = deepcopy(base_email_df)\n",
    "cleansed_email_df = rename_columns_remove_colon_from_column_name(cleansed_email_df)\n",
    "cleansed_email_df = extract_email_components_to_features(cleansed_email_df, ['to', 'from'])\n",
    "cleansed_email_df = exclude_invalid_to_from_subject_target_records(cleansed_email_df)\n",
    "cleansed_email_df = extract_content_type_info_from_content_type_records(cleansed_email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop after review\n",
    "# mime-version: no appreciable relevance - all values are 1 with an insignificant qty including additional info (approx 2%)\n",
    "# content-type: feature extraction is complete\n",
    "# Precedence: no appreciable relevance - no alignment between bulk and to_email_count and no obvious way to infer type. Possibly revisit or attempt to create a feature independently\n",
    "# Content-transfer-encoding: Not enough data to add menaingful information - 7 bit appears to have a higher frequency with HAM email.\n",
    "# x-mailer: emails with x-mailer seem more likely to be HAM but this can be explored further in future iterations.\n",
    "\n",
    "dropping = ['mime-version', 'content-type', 'precedence', 'content-transfer-encoding', 'x-mailer']\n",
    "cleansed_email_df.drop(dropping, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8517 entries, 0 to 9349\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   index                  8517 non-null   object \n",
      " 1   target                 8517 non-null   object \n",
      " 2   from                   8517 non-null   object \n",
      " 3   to                     8517 non-null   object \n",
      " 4   subject                8517 non-null   object \n",
      " 5   body                   8517 non-null   object \n",
      " 6   to_fullname            2403 non-null   object \n",
      " 7   to_email               8517 non-null   object \n",
      " 8   to_email_count         8517 non-null   float64\n",
      " 9   to_username            8517 non-null   object \n",
      " 10  to_domain              8517 non-null   object \n",
      " 11  from_fullname          7213 non-null   object \n",
      " 12  from_email             8517 non-null   object \n",
      " 13  from_email_count       8517 non-null   float64\n",
      " 14  from_username          8517 non-null   object \n",
      " 15  from_domain            8517 non-null   object \n",
      " 16  content-type-format    7646 non-null   object \n",
      " 17  content-type-type      7646 non-null   object \n",
      " 18  content-type-charset   5359 non-null   object \n",
      " 19  content-type-encoding  1262 non-null   object \n",
      "dtypes: float64(2), object(18)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cleansed_email_df.info())\n",
    "df = deepcopy(cleansed_email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\\nReferences: <1029945287.4797.TMDA@deepeddy.vircio.com>\\n<1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\\n<1029943066.26919.TMDA@deepeddy.vircio.com>\\n<1029944441.398.TMDA@deepeddy.vircio.com>\\nMIME-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nMessage-Id: <13258.1030015585@munnari.OZ.AU>\\nX-Loop: exmh-workers@example.com\\nSender: exmh-workers-admin@example.com\\nErrors-To: exmh-workers-admin@example.com\\nX-Beenthere: exmh-workers@example.com\\nX-Mailman-Version: 2.0.1\\nPrecedence: bulk\\nList-Help: <mailto:exmh-workers-request@example.com?subject=help>\\nList-Post: <mailto:exmh-workers@example.com>\\nList-Subscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=subscribe>\\nList-Id: Discussion list for EXMH developers <exmh-workers.example.com>\\nList-Unsubscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\\nList-Archive: <https://listman.example.com/mailman/private/exmh-workers/>\\nDate: Thu, 22 Aug 2002 18:26:25 +0700\\n\\nDate:        Wed, 21 Aug 2002 10:54:46 -0500\\nFrom:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\\nMessage-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\\n\\n\\n| I can\\'t reproduce this error.\\n\\nFor me it is very repeatable... (like every time, without fail).\\n\\nThis is the debug log of the pick happening ...\\n\\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\\n18:19:04 Ftoc_PickMsgs {{1 hit}}\\n18:19:04 Marking 1 hits\\n18:19:04 tkerror: syntax error in expression \"int ...\\n\\nNote, if I run the pick command by hand ...\\n\\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\\n1 hit\\n\\nThat\\'s where the \"1 hit\" comes from (obviously).  The version of nmh I\\'m\\nusing is ...\\n\\ndelta$ pick -version\\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\\n\\nAnd the relevant part of my .mh_profile ...\\n\\ndelta$ mhparam pick\\n-seq sel -list\\n\\n\\nSince the pick command works, the sequence (actually, both of them, the\\none that\\'s explicit on the command line, from the search popup, and the\\none that comes from .mh_profile) do get created.\\n\\nkre\\n\\nps: this is still using the version of the code form a day ago, I haven\\'t\\nbeen able to reach the cvs repository today (local routing issue I think).\\n\\n\\n\\n_______________________________________________\\nExmh-workers mailing list\\nExmh-workers@redhat.com\\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words(df):\n",
    "    \"\"\"\n",
    "    Function to encapsulate the process of generating a list of unique cuisines from the cusines column.\n",
    "    Input:\n",
    "        df: target dataframe\n",
    "    Output:\n",
    "        unique_words: a list of all unique words contained in the body column of the target dataframe df.\n",
    "    \"\"\"\n",
    "    all_words = df[['body']].drop_duplicates()\n",
    "    all_words['split'] = all_words['body'].astype(str).map(lambda x: x.split(\" \"))\n",
    "    unique_words = (list(set([a.strip() for b in all_words['split'].tolist() for a in b])))\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_words_row(df_row):\n",
    "    return [a.strip() for a in re.split(r'[\\s,\\n\\.]+', df_row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_map(words, row):\n",
    "    \"\"\"\n",
    "    Passing in a list of unique cuisines that has been generated previously.\n",
    "    We compare the cuisines in a particular row and return a binary list of 0 for False, 1 for True in the cuisines is\n",
    "    in the row values.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [(a in row)*1 for a in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_words_df(df):\n",
    "    df_full = pd.DataFrame(df)\n",
    "    df_full = df_full[df_full['body'].notna()]\n",
    "    #print(df_full.head())\n",
    "    try:\n",
    "        df_full.reset_index(inplace = True)\n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "        print(\"Index not reset\")\n",
    "    mapping_dict = {}\n",
    "    unique_words = get_unique_words(df_full)\n",
    "    for i in range(df_full.shape[0]):\n",
    "        try:\n",
    "            df_row = prep_words_row(df_full['body'][i])\n",
    "        except:\n",
    "            print(df_full['body'][i])\n",
    "            print(type(df_full['body'][i]))\n",
    "        word_map = get_word_map(unique_words, df_row)\n",
    "        mapping_dict[df_full['index'][i]] = word_map\n",
    "    word_mapping_df = pd.DataFrame.from_dict(mapping_dict, orient = 'index', columns = unique_words)\n",
    "    return word_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-799a7119b473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_mapping_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_words_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_mapping_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-1c4eb1581d32>\u001b[0m in \u001b[0;36mparse_words_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mword_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mmapping_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_full\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mword_mapping_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-fe0b4d9febf2>\u001b[0m in \u001b[0;36mget_word_map\u001b[1;34m(words, row)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-fe0b4d9febf2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_mapping_df = parse_words_df(df)\n",
    "word_mapping_df.shapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words']= df['body'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_map = str.maketrans(dict.fromkeys(string.punctuation, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df['body'].str.translate(punc_map).str.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\\nReferences: <1029945287.4797.TMDA@deepeddy.vircio.com>\\n<1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\\n<1029943066.26919.TMDA@deepeddy.vircio.com>\\n<1029944441.398.TMDA@deepeddy.vircio.com>\\nMIME-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nMessage-Id: <13258.1030015585@munnari.OZ.AU>\\nX-Loop: exmh-workers@example.com\\nSender: exmh-workers-admin@example.com\\nErrors-To: exmh-workers-admin@example.com\\nX-Beenthere: exmh-workers@example.com\\nX-Mailman-Version: 2.0.1\\nPrecedence: bulk\\nList-Help: <mailto:exmh-workers-request@example.com?subject=help>\\nList-Post: <mailto:exmh-workers@example.com>\\nList-Subscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=subscribe>\\nList-Id: Discussion list for EXMH developers <exmh-workers.example.com>\\nList-Unsubscribe: <https://listman.example.com/mailman/listinfo/exmh-workers>,\\n<mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\\nList-Archive: <https://listman.example.com/mailman/private/exmh-workers/>\\nDate: Thu, 22 Aug 2002 18:26:25 +0700\\n\\nDate:        Wed, 21 Aug 2002 10:54:46 -0500\\nFrom:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\\nMessage-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\\n\\n\\n| I can\\'t reproduce this error.\\n\\nFor me it is very repeatable... (like every time, without fail).\\n\\nThis is the debug log of the pick happening ...\\n\\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\\n18:19:04 Ftoc_PickMsgs {{1 hit}}\\n18:19:04 Marking 1 hits\\n18:19:04 tkerror: syntax error in expression \"int ...\\n\\nNote, if I run the pick command by hand ...\\n\\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\\n1 hit\\n\\nThat\\'s where the \"1 hit\" comes from (obviously).  The version of nmh I\\'m\\nusing is ...\\n\\ndelta$ pick -version\\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\\n\\nAnd the relevant part of my .mh_profile ...\\n\\ndelta$ mhparam pick\\n-seq sel -list\\n\\n\\nSince the pick command works, the sequence (actually, both of them, the\\none that\\'s explicit on the command line, from the search popup, and the\\none that comes from .mh_profile) do get created.\\n\\nkre\\n\\nps: this is still using the version of the code form a day ago, I haven\\'t\\nbeen able to reach the cvs repository today (local routing issue I think).\\n\\n\\n\\n_______________________________________________\\nExmh-workers mailing list\\nExmh-workers@redhat.com\\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InReplyTo',\n",
       " '10299452874797TMDAdeepeddyvirciocom\\nReferences',\n",
       " '10299452874797TMDAdeepeddyvirciocom\\n10298824683116TMDAdeepeddyvirciocom',\n",
       " '96271029933001munnariOZAU\\n102994306626919TMDAdeepeddyvirciocom\\n1029944441398TMDAdeepeddyvirciocom\\nMIMEVersion',\n",
       " '10\\nContentType',\n",
       " 'textplain',\n",
       " 'charsetusascii\\nMessageId',\n",
       " '132581030015585munnariOZAU\\nXLoop',\n",
       " 'exmhworkersexamplecom\\nSender',\n",
       " 'exmhworkersadminexamplecom\\nErrorsTo',\n",
       " 'exmhworkersadminexamplecom\\nXBeenthere',\n",
       " 'exmhworkersexamplecom\\nXMailmanVersion',\n",
       " '201\\nPrecedence',\n",
       " 'bulk\\nListHelp',\n",
       " 'mailtoexmhworkersrequestexamplecomsubjecthelp\\nListPost',\n",
       " 'mailtoexmhworkersexamplecom\\nListSubscribe',\n",
       " 'httpslistmanexamplecommailmanlistinfoexmhworkers\\nmailtoexmhworkersrequestredhatcomsubjectsubscribe\\nListId',\n",
       " 'Discussion',\n",
       " 'list',\n",
       " 'for',\n",
       " 'EXMH',\n",
       " 'developers',\n",
       " 'exmhworkersexamplecom\\nListUnsubscribe',\n",
       " 'httpslistmanexamplecommailmanlistinfoexmhworkers\\nmailtoexmhworkersrequestredhatcomsubjectunsubscribe\\nListArchive',\n",
       " 'httpslistmanexamplecommailmanprivateexmhworkers\\nDate',\n",
       " 'Thu',\n",
       " '22',\n",
       " 'Aug',\n",
       " '2002',\n",
       " '182625',\n",
       " '0700\\n\\nDate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Wed',\n",
       " '21',\n",
       " 'Aug',\n",
       " '2002',\n",
       " '105446',\n",
       " '0500\\nFrom',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Chris',\n",
       " 'Garrigues',\n",
       " 'cwgdated103037728706fa6dDeepEddyCom\\nMessageID',\n",
       " '',\n",
       " '10299452874797TMDAdeepeddyvirciocom\\n\\n\\n',\n",
       " 'I',\n",
       " 'cant',\n",
       " 'reproduce',\n",
       " 'this',\n",
       " 'error\\n\\nFor',\n",
       " 'me',\n",
       " 'it',\n",
       " 'is',\n",
       " 'very',\n",
       " 'repeatable',\n",
       " 'like',\n",
       " 'every',\n",
       " 'time',\n",
       " 'without',\n",
       " 'fail\\n\\nThis',\n",
       " 'is',\n",
       " 'the',\n",
       " 'debug',\n",
       " 'log',\n",
       " 'of',\n",
       " 'the',\n",
       " 'pick',\n",
       " 'happening',\n",
       " '\\n\\n181903',\n",
       " 'PickIt',\n",
       " 'exec',\n",
       " 'pick',\n",
       " 'inbox',\n",
       " 'list',\n",
       " 'lbrace',\n",
       " 'lbrace',\n",
       " 'subject',\n",
       " 'ftp',\n",
       " 'rbrace',\n",
       " 'rbrace',\n",
       " '48524852',\n",
       " 'sequence',\n",
       " 'mercury\\n181903',\n",
       " 'exec',\n",
       " 'pick',\n",
       " 'inbox',\n",
       " 'list',\n",
       " 'lbrace',\n",
       " 'lbrace',\n",
       " 'subject',\n",
       " 'ftp',\n",
       " 'rbrace',\n",
       " 'rbrace',\n",
       " '48524852',\n",
       " 'sequence',\n",
       " 'mercury\\n181904',\n",
       " 'FtocPickMsgs',\n",
       " '1',\n",
       " 'hit\\n181904',\n",
       " 'Marking',\n",
       " '1',\n",
       " 'hits\\n181904',\n",
       " 'tkerror',\n",
       " 'syntax',\n",
       " 'error',\n",
       " 'in',\n",
       " 'expression',\n",
       " 'int',\n",
       " '\\n\\nNote',\n",
       " 'if',\n",
       " 'I',\n",
       " 'run',\n",
       " 'the',\n",
       " 'pick',\n",
       " 'command',\n",
       " 'by',\n",
       " 'hand',\n",
       " '\\n\\ndelta',\n",
       " 'pick',\n",
       " 'inbox',\n",
       " 'list',\n",
       " 'lbrace',\n",
       " 'lbrace',\n",
       " 'subject',\n",
       " 'ftp',\n",
       " 'rbrace',\n",
       " 'rbrace',\n",
       " '',\n",
       " '48524852',\n",
       " 'sequence',\n",
       " 'mercury\\n1',\n",
       " 'hit\\n\\nThats',\n",
       " 'where',\n",
       " 'the',\n",
       " '1',\n",
       " 'hit',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'obviously',\n",
       " '',\n",
       " 'The',\n",
       " 'version',\n",
       " 'of',\n",
       " 'nmh',\n",
       " 'Im\\nusing',\n",
       " 'is',\n",
       " '\\n\\ndelta',\n",
       " 'pick',\n",
       " 'version\\npick',\n",
       " '',\n",
       " 'nmh104',\n",
       " 'compiled',\n",
       " 'on',\n",
       " 'fuchsiacsmuOZAU',\n",
       " 'at',\n",
       " 'Sun',\n",
       " 'Mar',\n",
       " '17',\n",
       " '145556',\n",
       " 'ICT',\n",
       " '2002\\n\\nAnd',\n",
       " 'the',\n",
       " 'relevant',\n",
       " 'part',\n",
       " 'of',\n",
       " 'my',\n",
       " 'mhprofile',\n",
       " '\\n\\ndelta',\n",
       " 'mhparam',\n",
       " 'pick\\nseq',\n",
       " 'sel',\n",
       " 'list\\n\\n\\nSince',\n",
       " 'the',\n",
       " 'pick',\n",
       " 'command',\n",
       " 'works',\n",
       " 'the',\n",
       " 'sequence',\n",
       " 'actually',\n",
       " 'both',\n",
       " 'of',\n",
       " 'them',\n",
       " 'the\\none',\n",
       " 'thats',\n",
       " 'explicit',\n",
       " 'on',\n",
       " 'the',\n",
       " 'command',\n",
       " 'line',\n",
       " 'from',\n",
       " 'the',\n",
       " 'search',\n",
       " 'popup',\n",
       " 'and',\n",
       " 'the\\none',\n",
       " 'that',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'mhprofile',\n",
       " 'do',\n",
       " 'get',\n",
       " 'created\\n\\nkre\\n\\nps',\n",
       " 'this',\n",
       " 'is',\n",
       " 'still',\n",
       " 'using',\n",
       " 'the',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'code',\n",
       " 'form',\n",
       " 'a',\n",
       " 'day',\n",
       " 'ago',\n",
       " 'I',\n",
       " 'havent\\nbeen',\n",
       " 'able',\n",
       " 'to',\n",
       " 'reach',\n",
       " 'the',\n",
       " 'cvs',\n",
       " 'repository',\n",
       " 'today',\n",
       " 'local',\n",
       " 'routing',\n",
       " 'issue',\n",
       " 'I',\n",
       " 'think\\n\\n\\n\\n\\nExmhworkers',\n",
       " 'mailing',\n",
       " 'list\\nExmhworkersredhatcom\\nhttpslistmanredhatcommailmanlistinfoexmhworkers\\n']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
